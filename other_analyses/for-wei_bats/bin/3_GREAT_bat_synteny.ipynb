{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6b32b18",
   "metadata": {},
   "source": [
    "20230630\n",
    "sarahfong\n",
    "\n",
    "My goal is to take bat enhancers that have been lifted over to human and found to have significant GREAT associations with nearby genes, and reverse flow. I will assess whether these bat elements are syntenic in bat genomes with the human enhancers+proximal genes linked in GREAT. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e753bbd5",
   "metadata": {},
   "source": [
    "        re-run GREAT on bat lifted to hg38 peaks. \n",
    "\n",
    "        liftover hg38 peaks → bat\n",
    "\n",
    "        convert TOGA gene ortholog chain → scaffold coordinates\n",
    "\n",
    "        compute within-scaffolds TOGA-guided intergenic regions for bats\n",
    "\n",
    "        Assess how often human element-nearest-gene pair is the same as bat element-nearest-gene pair. \n",
    "\n",
    "**Nadav’s note** - selected elements that were on big scaffolds. Possible that some genes are on different scaffolds than their elements. In this case, we’re going to have to black list these regions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0a1a2fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T16:32:27.879796Z",
     "start_time": "2023-07-18T16:32:08.460128Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sans-serif', 'Arial', 18)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from chr_functions import makeCoorAnnot\n",
    "import config_readwrite as crw\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import plot_params as pp\n",
    "pp.fonts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c67622",
   "metadata": {},
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3607c1f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T16:32:27.991358Z",
     "start_time": "2023-07-18T16:32:27.885452Z"
    }
   },
   "outputs": [],
   "source": [
    "cfn_file = os.path.join(os.getcwd(), \"config.bats.ini\")\n",
    "\n",
    "config, cfn = crw.read(cfn_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eb906b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T16:32:28.316927Z",
     "start_time": "2023-07-18T16:32:27.996972Z"
    }
   },
   "outputs": [],
   "source": [
    "# peak file inputs\n",
    "\n",
    "PATH = config[\"local\"]['path_peak']\n",
    "\n",
    "section = \"hg38_peaks\"\n",
    "crw.check(config, section)\n",
    "\n",
    "HG_PATH = os.path.join(PATH, section)\n",
    "\n",
    "ART_KID = os.path.join(HG_PATH, \"Ajam.kidney.callpeaks.hg38-lift.bed\")\n",
    "ART_PAN = os.path.join(HG_PATH, \"Ajam.pancreas.callpeaks.revised2.cut.hg38-lift.bed\")\n",
    "EPT_KID = os.path.join(HG_PATH, \"Efus.kidney.callpeaks.hg38-lift.bed\")\n",
    "EPT_PAN = os.path.join(HG_PATH, \"Efus.pancreas.callpeaks.revised2.ucsc.hg38-lift.bed\")\n",
    "\n",
    "write_dict={'path':HG_PATH, \n",
    "            \"ART_KID\":ART_KID,\n",
    "            \"ART_PAN\":ART_PAN,\n",
    "            \"EPT_KID\":EPT_KID,\n",
    "            \"EPT_PAN\":EPT_PAN,\n",
    "                       }\n",
    "config = crw.writeConfigDict(write_dict, config, section)\n",
    "\n",
    "###\n",
    "# chain file inputs\n",
    "\n",
    "section = \"chains\"\n",
    "crw.check(config, section)\n",
    "\n",
    "CHAIN_PATH = os.path.join(PATH, section)\n",
    "# from  https://hgdownload.soe.ucsc.edu/goldenPath/hg38/vsEptFus1/hg38.eptFus1.all.chain.gz\n",
    "HG38_EPTFUS1 = os.path.join(CHAIN_PATH, \"hg38.eptFus1.all.chain.gz\")\n",
    "HG38_ARTJAM = os.path.join(\n",
    "    CHAIN_PATH, \"hg38.chr1_22.ArtJamW.chain.final\")  # from wei\n",
    "ARTJAM_HG38 = os.path.join(\n",
    "    CHAIN_PATH, \"ArtJamW.chr1_22.hg38.chain.final\")  # from wei\n",
    "\n",
    "write_dict = {\"HG38_EPTFUS1\": HG38_EPTFUS1,\n",
    "              \"HG38_ARTJAM\": HG38_ARTJAM,\n",
    "              \"ARTJAM_HG38\": ARTJAM_HG38\n",
    "              }\n",
    "config = crw.writeConfigDict(write_dict, config, section)\n",
    "\n",
    "###\n",
    "# liftover script \n",
    "section = \"liftover\"\n",
    "crw.check(config, section)\n",
    "\n",
    "LIFTOVER_SRC = \"/wynton/home/ahituv/fongsl/tools/evo/liftover_bed-wynton.py\"\n",
    "config[section][\"SRC\"] = LIFTOVER_SRC\n",
    "\n",
    "\n",
    "crw.write(config, cfn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1afbdc0",
   "metadata": {},
   "source": [
    "# format, liftover hg38 peaks file "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da36bff9",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631326d2",
   "metadata": {},
   "source": [
    " ### df formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "417a7b0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T16:32:28.632987Z",
     "start_time": "2023-07-18T16:32:28.320343Z"
    }
   },
   "outputs": [],
   "source": [
    "def formatBedForGreat(file, coor_id_name, formatted_filename):\n",
    "    \n",
    "    # name the columns\n",
    "    col_names = [\"#chr\", \"start\", \"end\"]\n",
    "\n",
    "    # open file as a dataframe\n",
    "    df = pd.read_csv(file, sep='\\t', header=None, usecols =[0,1,2], names = col_names)\n",
    "\n",
    "    # add hg38.coor using custom script, turn .bed fields into str(chr:start-end)\n",
    "    df = makeCoorAnnot(df, \"#chr\", \"start\", \"end\", coor_id_name)\n",
    "    \n",
    "    # sort the dataframe\n",
    "    df = df.sort_values(by=col_names)\n",
    "    \n",
    "    # save formatted bed file\n",
    "    if os.path.exists(formatted_filename) is False:\n",
    "        df.to_csv(formatted_filename, sep='\\t', index=False)\n",
    "        print(\"wrote\", formatted_filename)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d39b8cd",
   "metadata": {},
   "source": [
    "### liftover peaks function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "377cd1af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T16:33:01.194973Z",
     "start_time": "2023-07-18T16:33:01.189062Z"
    }
   },
   "outputs": [],
   "source": [
    "def liftOver(bed_file, to_build, from_build, minmatch, chainfile):\n",
    "\n",
    "    src = \"/wynton/home/ahituv/fongsl/tools/evo/liftover_bed-wynton.py\"\n",
    "    cmd = \" \".join([\n",
    "        \"python\", \n",
    "           src, \n",
    "           bed_file,\n",
    "           from_build, \n",
    "           to_build,\n",
    "           \"-m\", \n",
    "            minmatch,\n",
    "        \"-c\",\n",
    "        chainfile\n",
    "                    \n",
    "          ])\n",
    "\n",
    "    print(cmd)\n",
    "    \n",
    "    # run command in command line\n",
    "    os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96f44c5",
   "metadata": {},
   "source": [
    "##  params -  format, liftover "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d997f775",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T16:32:29.453978Z",
     "start_time": "2023-07-18T16:32:29.123334Z"
    }
   },
   "outputs": [],
   "source": [
    "BEDS = {\"ART_KID\":ART_KID, \n",
    "        \"ART_PAN\":ART_PAN, \n",
    "        \"EPT_KID\": EPT_KID, \n",
    "        \"EPT_PAN\":EPT_PAN\n",
    "       }\n",
    "\n",
    "liftover_runs = {\n",
    "    \"ART_KID\":(\"hg38\", \"artJam2\", HG38_ARTJAM), \n",
    "    \"ART_PAN\":(\"hg38\", \"artJam2\", HG38_ARTJAM), \n",
    "    \"EPT_KID\":(\"hg38\", \"eptFus1\", HG38_EPTFUS1), \n",
    "    \"EPT_PAN\":(\"hg38\", \"eptFus1\", HG38_EPTFUS1)\n",
    "}\n",
    "\n",
    "BUILD = \"hg38\"\n",
    "MINMATCH = \"0.1\"\n",
    "section = \"hg38_peaks\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9650a96",
   "metadata": {},
   "source": [
    "## iterate through peak.bed files\n",
    " - format bed files\n",
    " - liftover formatted bed files from hg38 -> bat genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "797d493d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T16:33:22.114745Z",
     "start_time": "2023-07-18T16:33:09.524494Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python /wynton/home/ahituv/fongsl/tools/evo/liftover_bed-wynton.py /wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/hg38_peaks/Ajam.kidney.peaks.clean.hg38.bed hg38 artJam2 -m 0.1 -c /wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/chains/hg38.chr1_22.ArtJamW.chain.final\n",
      "/wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/hg38_peaks 0.1 <class 'str'>\n",
      "\n",
      "\n",
      "lifting over /wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/hg38_peaks/Ajam.kidney.peaks.clean.hg38.bed from hg38 to artJam2 in /wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/hg38_peaks \n",
      "\n",
      "\n",
      "Sorting .bed /wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/hg38_peaks/temp_Ajam.kidney.peaks.clean.hg38.bed\n",
      "lifted this already?\n",
      "\n",
      " /wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/hg38_peaks/Ajam.kidney.peaks.clean.hg38.liftOver.to.artJam2.bed\n",
      "cleaned up temp file\n",
      "python /wynton/home/ahituv/fongsl/tools/evo/liftover_bed-wynton.py /wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/hg38_peaks/Ajam.pancreas.peaks.clean.hg38.bed hg38 artJam2 -m 0.1 -c /wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/chains/hg38.chr1_22.ArtJamW.chain.final\n",
      "/wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/hg38_peaks 0.1 <class 'str'>\n",
      "\n",
      "\n",
      "lifting over /wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/hg38_peaks/Ajam.pancreas.peaks.clean.hg38.bed from hg38 to artJam2 in /wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/hg38_peaks \n",
      "\n",
      "\n",
      "Sorting .bed /wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/hg38_peaks/temp_Ajam.pancreas.peaks.clean.hg38.bed\n",
      "lifted this already?\n",
      "\n",
      " /wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/hg38_peaks/Ajam.pancreas.peaks.clean.hg38.liftOver.to.artJam2.bed\n",
      "cleaned up temp file\n",
      "python /wynton/home/ahituv/fongsl/tools/evo/liftover_bed-wynton.py /wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/hg38_peaks/Efus.kidney.peaks.clean.hg38.bed hg38 eptFus1 -m 0.1 -c /wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/chains/hg38.eptFus1.all.chain.gz\n",
      "/wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/hg38_peaks 0.1 <class 'str'>\n",
      "\n",
      "\n",
      "lifting over /wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/hg38_peaks/Efus.kidney.peaks.clean.hg38.bed from hg38 to eptFus1 in /wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/hg38_peaks \n",
      "\n",
      "\n",
      "Sorting .bed /wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/hg38_peaks/temp_Efus.kidney.peaks.clean.hg38.bed\n",
      "lifted this already?\n",
      "\n",
      " /wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/hg38_peaks/Efus.kidney.peaks.clean.hg38.liftOver.to.eptFus1.bed\n",
      "cleaned up temp file\n",
      "python /wynton/home/ahituv/fongsl/tools/evo/liftover_bed-wynton.py /wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/hg38_peaks/Efus.pancreas.peaks.clean.hg38.bed hg38 eptFus1 -m 0.1 -c /wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/chains/hg38.eptFus1.all.chain.gz\n",
      "/wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/hg38_peaks 0.1 <class 'str'>\n",
      "\n",
      "\n",
      "lifting over /wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/hg38_peaks/Efus.pancreas.peaks.clean.hg38.bed from hg38 to eptFus1 in /wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/hg38_peaks \n",
      "\n",
      "\n",
      "Sorting .bed /wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/hg38_peaks/temp_Efus.pancreas.peaks.clean.hg38.bed\n",
      "lifted this already?\n",
      "\n",
      " /wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/hg38_peaks/Efus.pancreas.peaks.clean.hg38.liftOver.to.eptFus1.bed\n",
      "cleaned up temp file\n"
     ]
    }
   ],
   "source": [
    "for name, file in BEDS.items():\n",
    "    \n",
    "    # make a new file\n",
    "    OUT_PATH, NAME = os.path.split(file)\n",
    "    OUT_FILE= os.path.join(OUT_PATH, \".\".join(NAME.split(\".\")[:2]) + f\".peaks.clean.{BUILD}.bed\")\n",
    "    \n",
    "    # write to config\n",
    "    config[section][f\"{name}.clean\"]= OUT_FILE\n",
    "    crw.write(config, cfn)\n",
    "    \n",
    "    # format the bed file\n",
    "    formatBedForGreat(file, BUILD, OUT_FILE)\n",
    "    \n",
    "    # get the to and from builds, chainfile for this species\n",
    "    from_build, to_build, chainf = liftover_runs[name]\n",
    "    \n",
    "    # do liftover\n",
    "    liftOver(OUT_FILE, to_build, from_build, LIFTOVER_SRC, MINMATCH, chainf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e3c68d",
   "metadata": {},
   "source": [
    "## add liftOver peak files to config. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e2fbc83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T16:33:22.131621Z",
     "start_time": "2023-07-18T16:33:22.120603Z"
    }
   },
   "outputs": [],
   "source": [
    "section = \"liftover\"\n",
    "crw.check(config, section)\n",
    "\n",
    "EFUS_KID_CLEAN_LIFT = os.path.join(HG_PATH, \"Efus.kidney.peaks.clean.hg38.liftOver.to.eptFus1.bed\")\n",
    "EFUS_PAN_CLEAN_LIFT  = os.path.join(HG_PATH, \"Efus.pancreas.peaks.clean.hg38.liftOver.to.eptFus1.bed\")\n",
    "\n",
    "ept_peaks = {\n",
    "    \"EFUS_KID_CLEAN_LIFT\":EFUS_KID_CLEAN_LIFT ,\n",
    "    \"EFUS_PAN_CLEAN_LIFT\":EFUS_PAN_CLEAN_LIFT ,\n",
    "    \n",
    "}\n",
    "\n",
    "config = crw.writeConfigDict(ept_peaks, config, section)\n",
    "\n",
    "\n",
    "AJAM_KID_CLEAN_LIFT  = os.path.join(HG_PATH, \"Ajam.kidney.peaks.clean.hg38.liftOver.to.artJam2.bed\")\n",
    "AJAM_PAN_CLEAN_LIFT  = os.path.join(HG_PATH, \"Ajam.pancreas.peaks.clean.hg38.liftOver.to.artJam2.bed\")\n",
    "\n",
    "ajam_peaks = {\n",
    "    \"AJAM_KID_CLEAN_LIFT\":AJAM_KID_CLEAN_LIFT ,\n",
    "    \"AJAM_PAN_CLEAN_LIFT\":AJAM_PAN_CLEAN_LIFT ,\n",
    "    \n",
    "}\n",
    "\n",
    "config = crw.writeConfigDict(ajam_peaks, config, section)\n",
    "crw.write(config, cfn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed581a36",
   "metadata": {},
   "source": [
    "# format scaffold files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a16239a",
   "metadata": {},
   "source": [
    "## add to config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76828426",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T16:33:22.390280Z",
     "start_time": "2023-07-18T16:33:22.134325Z"
    }
   },
   "outputs": [],
   "source": [
    "section = \"scaffolds\"\n",
    "\n",
    "# make section\n",
    "crw.check(config, section)\n",
    "\n",
    "# get path to scaffolds\n",
    "SCAF_PATH = config[\"local\"][\"path_scaf\"]\n",
    "\n",
    "# get scaffold mappings\n",
    "AJAM_SCAF = os.path.join(\n",
    "    SCAF_PATH, \"GCF_014825515.1_WHU_Ajam_v2_assembly_report.txt\")\n",
    "\n",
    "EPT_SCAF = os.path.join(SCAF_PATH, \"replace_efus-ucsc_with_efus-ncbi.txt\")\n",
    "\n",
    "AJAM_SCAF_CLEAN = os.path.join(\n",
    "    SCAF_PATH, 'artJam2.chain.scaffold.map.clean.txt')\n",
    "\n",
    "EPT_SCAF_CLEAN = os.path.join(\n",
    "    SCAF_PATH, 'eptFus1.chain.scaffold.map.clean.txt')\n",
    "\n",
    "scaffold_dict = {\n",
    "    \"AJAM_SCAF\": AJAM_SCAF,\n",
    "    \"EPT_SCAF\": EPT_SCAF,\n",
    "    \"AJAM_SCAF_CLEAN\": AJAM_SCAF_CLEAN,\n",
    "    \"EPT_SCAF_CLEAN\": EPT_SCAF_CLEAN,\n",
    "}\n",
    "\n",
    "config = crw.writeConfigDict(scaffold_dict, config, section)\n",
    "crw.write(config, cfn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9c47c4",
   "metadata": {},
   "source": [
    "## params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61e80316",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T16:33:22.625874Z",
     "start_time": "2023-07-18T16:33:22.395199Z"
    }
   },
   "outputs": [],
   "source": [
    "scaffolds={\"artJam\": (AJAM_SCAF, AJAM_SCAF_CLEAN),\n",
    "           \"eptFus\":(EPT_SCAF, EPT_SCAF_CLEAN),\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5389601e",
   "metadata": {},
   "source": [
    "## format scaffold files into two columns\n",
    "- chain, scaffold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfcc56e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T16:33:23.371260Z",
     "start_time": "2023-07-18T16:33:22.629923Z"
    }
   },
   "outputs": [],
   "source": [
    "for key, value in scaffolds.items():\n",
    "\n",
    "    infile, outfile = value # unpack tuple\n",
    "    \n",
    "    col_names=[\"#chain\", \"scaffold\"]\n",
    "    \n",
    "    if key ==\"eptFus\":\n",
    "        df = pd.read_csv(infile, sep=\"/\", header=None, usecols =[1,2], names=col_names)\n",
    "\n",
    "    elif key == \"artJam\":\n",
    "        df = pd.read_csv(infile, sep='\\t', usecols = [\"GenBank-Accn\", \"RefSeq-Accn\"])\n",
    "\n",
    "        # rename\n",
    "        df.columns = col_names\n",
    "        \n",
    "    df.to_csv(outfile, sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63efd6a2",
   "metadata": {},
   "source": [
    "# map TOGA GENE ORTHOLOG chains to scaffolds \n",
    "- convert scaffold files to a .tsv format w/ two columns: chain, scaffold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba0f173",
   "metadata": {},
   "source": [
    "## function - add scaffold, make .bed file with scaffold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad7daeae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T16:33:23.389775Z",
     "start_time": "2023-07-18T16:33:23.375419Z"
    }
   },
   "outputs": [],
   "source": [
    "def addScaffold(ortho_file, scaffold_file, species):\n",
    "    \"\"\"\n",
    "    add scaffold information to TOGA ortholog chain annotations\n",
    "    make into a .bed file\n",
    "\n",
    "    input\n",
    "        ortho_file (str) - TOGA gene ortholog prediction file (where chr is chain id)\n",
    "        scaffold_file (str) - scaffold:chain mapping file (made above)\n",
    "\n",
    "    method\n",
    "        1. make an outfile to write .bed w/ ortholog gene coordinates AND scaffold as chromosome. \n",
    "        2. open the scaffold file\n",
    "            2.1 reformat chain column for merging\n",
    "        3. open ortholog file\n",
    "            3.1 get gene name\n",
    "        4. merge scaffold + ortholog file\n",
    "            4.1 check that the ortholog file has not lost any information\n",
    "        5. rearrange columns so that scaffold is in #chr position in bed file\n",
    "            5.1 rename the scaffold column w a hash, \n",
    "            # drop enst annotation - duplicates of many genes\n",
    "        6. write merged file if not already written.\n",
    "\n",
    "    return\n",
    "        merged (pd dataframe) - ortholog info w/ scaffold info added\n",
    "        ortho_out (str) - path to written .bed file w/ ortholog + scaffold info. \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # 1 make new .bed file to write\n",
    "    ortho_out = os.path.splitext(ortho_file)[0].strip(\n",
    "        \".bed\") + \".w.scaffold.bed\"\n",
    "\n",
    "    # 2\n",
    "    scaf = pd.read_csv(scaffold_file, sep='\\t')\n",
    "\n",
    "    # 2.1\n",
    "    scaf[\"chain\"] = scaf[\"#chain\"].apply(lambda x: x.split(\".\")[0])\n",
    "\n",
    "    # 3\n",
    "    ortho = pd.read_csv(ortho_file, sep='\\t',\n",
    "                        header=None, usecols=[0, 1, 2, 3],\n",
    "                        names=[\"chain\", \"start\", \"end\", \"enst\"]\n",
    "                        )\n",
    "    # 3.1\n",
    "    ortho[\"gene_name\"] = ortho[\"enst\"].apply(lambda x: x.split(\".\")[1])\n",
    "\n",
    "    # 4 add scaffold info via chain info\n",
    "    merged = pd.merge(ortho, scaf)\n",
    "\n",
    "    # 4.1 check that there is no data loss after merge\n",
    "    print(ortho.shape, merged.shape)\n",
    "\n",
    "    # 5 rearrange as .bed\n",
    "    if species == \"eptfus1\":\n",
    "\n",
    "        # drop enst annotation - keeping enst annotation produces duplicates of many genes\n",
    "        merged = merged[['chain', 'start', 'end',\n",
    "                         'gene_name', '#chain', 'scaffold']].drop_duplicates()  # ugh. The golden path liftover uses chain as #chr, not scaffold for eptfus1...\n",
    "        merged.sort_values(by=['chain', 'start', 'end'])\n",
    "\n",
    "        # 5.1 rename column\n",
    "        merged = merged.rename(columns={\"chain\": \"#chain\",\n",
    "                                        \"#chain\": \"chain_\"})\n",
    "\n",
    "    else:\n",
    "        merged = merged[['scaffold', 'start', 'end',\n",
    "                         'gene_name', '#chain', 'chain']].drop_duplicates()\n",
    "\n",
    "        # 5.1 rename column\n",
    "        merged = merged.rename(columns={\"scaffold\": \"#scaffold\"})\n",
    "\n",
    "        merged.sort_values(by=['#scaffold', 'start', 'end'])\n",
    "\n",
    "    # 6 write\n",
    "    # if os.path.exists(ortho_out) is False:\n",
    "    merged.to_csv(ortho_out, sep='\\t', index=False)\n",
    "\n",
    "    return merged, ortho_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b40fe1",
   "metadata": {},
   "source": [
    "## add scaffold info to TOGA gene ortholog prediction chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30965d05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T16:33:25.107424Z",
     "start_time": "2023-07-18T16:33:23.393276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hlartjam2\n",
      "(66067, 5) (66067, 7)\n",
      "/wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/toga/HLartJam2.hg38-ref.geneAnnotation.w.scaffold.bed\n",
      "eptfus1\n",
      "(53938, 5) (53938, 7)\n",
      "/wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/toga/eptFus1.hg38-ref.geneAnnotation.w.scaffold.bed\n"
     ]
    }
   ],
   "source": [
    "# params - human only\n",
    "gene_ortho = {\"local_toga-human_hg38_reference\":\n",
    "              [('hlartjam2.geneannotation.bed.gz',AJAM_SCAF_CLEAN),\n",
    "               ('eptfus1.geneannotation.bed.gz', EPT_SCAF_CLEAN)]\n",
    "              }\n",
    "\n",
    "# add scaffold info\n",
    "for section, orthofiles in gene_ortho.items():\n",
    "\n",
    "    for orthoval, scaffold_file in orthofiles:\n",
    "\n",
    "        species = orthoval.split(\".\")[0]\n",
    "        print(species)\n",
    "\n",
    "        # get the gene ortholog file\n",
    "        ortho_file = config[section][orthoval]\n",
    "    \n",
    "        # merge TOGA gene ortholog chains + scaffolds\n",
    "        merged, ortho_out = addScaffold(ortho_file, scaffold_file, species)\n",
    "        \n",
    "        # write to config\n",
    "        config[section][f\"gene_scaffold_{species}\"] = ortho_out\n",
    "        print(ortho_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92311dc2",
   "metadata": {},
   "source": [
    "# intersect bat peaks with nearest TOGA ortholog gene "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dde3ac3",
   "metadata": {},
   "source": [
    "## bedtools sort and closest upstream, downstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "159fccd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T16:33:30.030383Z",
     "start_time": "2023-07-18T16:33:25.109575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " /wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/hg38_peaks/efus_kid_clean_lift.x.gene_scaffold_eptfus1.bed\n",
      "\n",
      "\n",
      " /wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/hg38_peaks/efus_pan_clean_lift.x.gene_scaffold_eptfus1.bed\n",
      "\n",
      "\n",
      " /wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/hg38_peaks/ajam_kid_clean_lift.x.gene_scaffold_hlartjam2.bed\n",
      "\n",
      "\n",
      " /wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/hg38_peaks/ajam_pan_clean_lift.x.gene_scaffold_hlartjam2.bed\n"
     ]
    }
   ],
   "source": [
    "int_pairs = {\"efus_kid_clean_lift\": \"gene_scaffold_eptfus1\",\n",
    "             \"efus_pan_clean_lift\": \"gene_scaffold_eptfus1\",\n",
    "             \"ajam_kid_clean_lift\": \"gene_scaffold_hlartjam2\",\n",
    "             \"ajam_pan_clean_lift\": \"gene_scaffold_hlartjam2\",\n",
    "             }\n",
    "\n",
    "collection = {} ## collect results\n",
    "\n",
    "for peak, ortho_gene in int_pairs.items():\n",
    "    PEAK = config[\"liftover\"][peak]\n",
    "    ORTHO_GENE = config[\"local_toga-human_hg38_reference\"][ortho_gene]\n",
    "\n",
    "    ID = f\"{peak}.x.{ortho_gene}\"\n",
    "    OUT= os.path.join(HG_PATH, f\"{ID}.bed\")\n",
    "\n",
    "    for FILE in [PEAK, ORTHO_GENE]:\n",
    "\n",
    "        # sort\n",
    "        cmd = \" \".join([\"bedtools sort -i\",\n",
    "                        FILE,\n",
    "                        \"> t && mv t\",\n",
    "                        FILE\n",
    "                        ])\n",
    "        #print(\"\\n\\nsort\", cmd)\n",
    "        os.system(cmd)\n",
    "\n",
    "    \n",
    "    # find closest upstream, downst\n",
    "    flags = [\"-fu\",\"-fd\"]\n",
    "    \n",
    "    # bedtools closest\n",
    "    for flag in flags:\n",
    "\n",
    "        cmd = \" \".join([\"bedtools closest -a\",\n",
    "                        PEAK,\n",
    "                        \"-b\",\n",
    "                        ORTHO_GENE,\n",
    "                        flag,\n",
    "                        \"-D 'a' >>\",\n",
    "                        OUT\n",
    "                        ])\n",
    "    #print(\"\\n\\nclosest\", cmd)\n",
    "    #os.system(cmd)\n",
    "\n",
    "    print(\"\\n\\n\", OUT)\n",
    "    # add to collection dictionary\n",
    "    collection[ID]=OUT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ed932d",
   "metadata": {},
   "source": [
    "## write bat nearest gene section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f7eaa5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T16:33:30.038880Z",
     "start_time": "2023-07-18T16:33:30.032976Z"
    }
   },
   "outputs": [],
   "source": [
    "# write bat nearest gene section\n",
    "section = \"nearest_gene\"\n",
    "crw.check(config, section)\n",
    "\n",
    "config = crw.writeConfigDict(collection, config, section)\n",
    "crw.write(config, cfn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589ff1d9",
   "metadata": {},
   "source": [
    "## write human nearest gene section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf1f962e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T16:33:30.316820Z",
     "start_time": "2023-07-18T16:33:30.045019Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH_GREAT = os.path.join(HG_PATH, \"great\")\n",
    "AJAM_KID_HU_GENE = os.path.join(PATH_GREAT, \"Ajam.kidney.peaks.clean.hg38-all-region.txt\")\n",
    "AJAM_PAN_HU_GENE = os.path.join(PATH_GREAT, \"Ajam.pancreas.peaks.clean.hg38-all-region.txt\")\n",
    "EFUS_KID_HU_GENE = os.path.join(PATH_GREAT, \"Efus.kidney.peaks.clean.hg38.all-region.txt\")\n",
    "EFUS_PAN_HU_GENE = os.path.join(PATH_GREAT, \"Efus.pancreas.peaks.clean.hg38-all-region.txt\")\n",
    "\n",
    "hu_nearest_gene = {\"path_great\":PATH_GREAT,\n",
    "                   \"AJAM_KID_HU_GENE\":AJAM_KID_HU_GENE,\n",
    "                   \"AJAM_PAN_HU_GENE\":AJAM_PAN_HU_GENE,\n",
    "                   \"EFUS_KID_HU_GENE\":EFUS_KID_HU_GENE,\n",
    "                   \"EFUS_PAN_HU_GENE\":EFUS_PAN_HU_GENE,\n",
    "\n",
    "}\n",
    "config = crw.writeConfigDict(hu_nearest_gene, config, section)\n",
    "crw.write(config, cfn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781f3517",
   "metadata": {},
   "source": [
    "# How often do nearest genes agree between humans and bats?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9296ec97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T16:33:30.562716Z",
     "start_time": "2023-07-18T16:33:30.320023Z"
    }
   },
   "outputs": [],
   "source": [
    "def aggregateGenesPerPeak(df, agg_col_name):\n",
    "\n",
    "    \"\"\"\n",
    "    aggregate agg_col_name into a single string col and return transformed dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    newdf = df.fillna(\"\")\n",
    "    return newdf.groupby(\"hg38.coor\").agg({agg_col_name:lambda x: ','.join(x)} \\\n",
    "                                          if agg_col_name !=\"None\" else None).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3a98d08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T16:33:30.766632Z",
     "start_time": "2023-07-18T16:33:30.566275Z"
    }
   },
   "outputs": [],
   "source": [
    "def makeCoorGeneDf(df, column_list, new_col):\n",
    "    \"\"\"\n",
    "    return dataframe of just hg38 peak coordinates + nearest gene names\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # melt dataframe\n",
    "    newdf = pd.melt(df, id_vars=[\"hg38.coor\"],\n",
    "                    value_vars=column_list, value_name=new_col)\n",
    "\n",
    "    # keep only coordinates, gene names\n",
    "    newdf = newdf[[\"hg38.coor\", new_col]].drop_duplicates()\n",
    "\n",
    "    # aggregate nearest genes\n",
    "    newdf_agg = aggregateGenesPerPeak(newdf, new_col)\n",
    "    \n",
    "    # report results\n",
    "    print(newdf.shape, newdf_agg.shape)\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    return newdf, newdf_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c75ea8e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T16:33:31.047037Z",
     "start_time": "2023-07-18T16:33:30.769970Z"
    }
   },
   "outputs": [],
   "source": [
    "def computeSynteny(hudf, batdf):\n",
    "    \"\"\"\n",
    "    merge human and bat nearest gene orthologs on the human peak annotation.\n",
    "    Count how many rows (peak:hu-gene v. peak:bat-gene) agree/don't agree\n",
    "\n",
    "    annotate how many hu/bat nearest gene orthologs agree\n",
    "\n",
    "    input \n",
    "        hudf (pd dataframe): dataframe with human peak coordinates and human nearest genes\n",
    "        batdf (pd dataframe): dataframe with bat peak coordinates (in hg38) and bat nearest genes\n",
    "\n",
    "    method\n",
    "        1. merge hudf and batdf on peak id\n",
    "        2. compute how many peak agree on nearest hu gene, nearest bat gene name (i.e. True)\n",
    "        3. compute how many peaks do not agree on nearest hu gene, nearest bat gene name (i.w.False)\n",
    "        4. determine not syntenic, where peak id is in False, but not in True\n",
    "        5. determine kindof syntenic, where peak id is both in False and True datasets\n",
    "        6. determine syntenic, where peak id is in True dataset, but not false\n",
    "    return\n",
    "        not_syn (set) - peak ids that are not syntenic\n",
    "        syn_kindof (set) - peak ids that have one nearest gene in common, but not two\n",
    "        syn_true (set) - peak ids that have both nearest genes in common. \n",
    "        merge (pd dataframe) - dataframe of peaks + human gene + bat gene\n",
    "\n",
    "    \"\"\"\n",
    "    # 1 merge bat and human nearst gene\n",
    "    merge = pd.merge(hudf, batdf).drop_duplicates()\n",
    "\n",
    "    # 2 determine if nearest genes are the same across rows\n",
    "    merge[\"agree\"] = merge['hu_nearest_gene'].str.strip().str.lower(\n",
    "    ) == merge[\"bat_nearest_gene\"].str.strip().str.lower()\n",
    "\n",
    "    # get coordinate ids where gene is the same\n",
    "    trues = set(merge.loc[merge[\"agree\"] == True, \"hg38.coor\"])\n",
    "\n",
    "    # 3 get coordinate ids where gene is different\n",
    "    falses = set(merge.loc[merge[\"agree\"] != True, \"hg38.coor\"])\n",
    "\n",
    "    # 4 determine synteny from sets that are all falses, combinations of true and fale, or all true\n",
    "    not_syn = falses.difference(trues)  # case where neither gene matches\n",
    "\n",
    "    # 5 case where one gene matches, but other does not\n",
    "    syn_kindof = falses.intersection(trues)\n",
    "\n",
    "    # 6 case where one gene matches, but other does not\n",
    "    syn_true = trues.difference(falses)\n",
    "\n",
    "    pairs = [(\"0/2 nearest gene is the same, n=\", len(not_syn)),\n",
    "             (\"1/2 nearest gene is the same, n=\", len(syn_kindof)),\n",
    "             (\"2/2 nearest gene is the same, n=\", len(syn_true))]\n",
    "    for i, j in pairs:\n",
    "        print(i, j)\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    return not_syn, syn_kindof, syn_true, merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22c395e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T16:33:31.273704Z",
     "start_time": "2023-07-18T16:33:31.050370Z"
    }
   },
   "outputs": [],
   "source": [
    "def getBatGenes(gene_set, mergedf, outfile):\n",
    "    nearest_genes = mergedf.loc[mergedf[\"hg38.coor\"].isin(gene_set) &\n",
    "                               mergedf['agree']==True].drop_duplicates()\n",
    "    \n",
    "    nearest_genes.to_csv(outfile, sep='\\t', index=False)\n",
    "    \n",
    "    return nearest_genes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41be32cc",
   "metadata": {},
   "source": [
    "## compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0b582c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T16:34:05.285442Z",
     "start_time": "2023-07-18T16:33:31.277158Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EFUS_KID_HU_GENE\n",
      "(283282, 2) (141641, 2)\n",
      "\n",
      "\n",
      "\n",
      "(142879, 2) (139822, 2)\n",
      "\n",
      "\n",
      "\n",
      "0/2 nearest gene is the same, n= 56883\n",
      "1/2 nearest gene is the same, n= 82939\n",
      "2/2 nearest gene is the same, n= 0\n",
      "\n",
      "\n",
      "\n",
      "/wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/hg38_peaks/NEAREST_MATCHED.EFUS_KID_HU_GENE_BAT_GENE.tsv\n",
      "EFUS_PAN_HU_GENE\n",
      "(222772, 2) (111386, 2)\n",
      "\n",
      "\n",
      "\n",
      "(112094, 2) (109751, 2)\n",
      "\n",
      "\n",
      "\n",
      "0/2 nearest gene is the same, n= 45397\n",
      "1/2 nearest gene is the same, n= 64354\n",
      "2/2 nearest gene is the same, n= 0\n",
      "\n",
      "\n",
      "\n",
      "/wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/hg38_peaks/NEAREST_MATCHED.EFUS_PAN_HU_GENE_BAT_GENE.tsv\n",
      "AJAM_KID_HU_GENE\n",
      "(249682, 2) (124841, 2)\n",
      "\n",
      "\n",
      "\n",
      "(116314, 2) (113760, 2)\n",
      "\n",
      "\n",
      "\n",
      "0/2 nearest gene is the same, n= 41704\n",
      "1/2 nearest gene is the same, n= 72055\n",
      "2/2 nearest gene is the same, n= 1\n",
      "\n",
      "\n",
      "\n",
      "/wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/hg38_peaks/NEAREST_MATCHED.AJAM_KID_HU_GENE_BAT_GENE.tsv\n",
      "{'chr6:127518941-127519369'}\n",
      "AJAM_PAN_HU_GENE\n",
      "(368694, 2) (184347, 2)\n",
      "\n",
      "\n",
      "\n",
      "(171443, 2) (167773, 2)\n",
      "\n",
      "\n",
      "\n",
      "0/2 nearest gene is the same, n= 61542\n",
      "1/2 nearest gene is the same, n= 106230\n",
      "2/2 nearest gene is the same, n= 1\n",
      "\n",
      "\n",
      "\n",
      "/wynton/home/ahituv/fongsl/other_analyses/for-wei_bats/data/peaks/hg38_peaks/NEAREST_MATCHED.AJAM_PAN_HU_GENE_BAT_GENE.tsv\n",
      "{'chr6:127518712-127519520'}\n"
     ]
    }
   ],
   "source": [
    "peak_gene_dict = {\n",
    "    \"efus_kid_clean_lift.x.gene_scaffold_eptfus1\": \"EFUS_KID_HU_GENE\",\n",
    "    \"efus_pan_clean_lift.x.gene_scaffold_eptfus1\": \"EFUS_PAN_HU_GENE\",\n",
    "    \"ajam_kid_clean_lift.x.gene_scaffold_hlartjam2\": \"AJAM_KID_HU_GENE\",\n",
    "    \"ajam_pan_clean_lift.x.gene_scaffold_hlartjam2\": \"AJAM_PAN_HU_GENE\",\n",
    "\n",
    "}\n",
    "\n",
    "# per peak\n",
    "for bat_, hu_ in peak_gene_dict.items():\n",
    "    print(hu_)\n",
    "\n",
    "    # read config for peak-gene files\n",
    "    # bat peaks (coded as human peaks) + closest TOGA gene ortholog\n",
    "    BAT = config[section][bat_]\n",
    "    # human peak (coded as human peaks) + closest GREAT genes\n",
    "    HU = config[section][hu_]\n",
    "\n",
    "    # open dataframes\n",
    "    bat = pd.read_csv(BAT, sep='\\t', header=None, usecols=[3, 7],\n",
    "                      names=[\"hg38.coor\", \"gene_name\"])\n",
    "\n",
    "    hu = pd.read_csv(HU, sep='\\t', header=None, skiprows=1,\n",
    "                     names=[\"hg38.coor\", \"hu_nearest_genes\"])\n",
    "\n",
    "    # format human gene pairs\n",
    "    hu[\"gene1\"] = hu[\"hu_nearest_genes\"].apply(lambda x: x.split(\"(\")[0])\n",
    "    hu[\"gene2\"] = hu[\"hu_nearest_genes\"].apply(lambda x: (\n",
    "        x.split(\",\")[1]).split(\"(\")[0] if len(x.split(\",\")) > 1 else None)\n",
    "\n",
    "    # make dataframe human nearest genes to peak\n",
    "\n",
    "    new_col = \"hu_nearest_gene\"\n",
    "    in_df = hu.copy()\n",
    "    column_list = list(in_df.columns[2:])\n",
    "    hum, hum_agg = makeCoorGeneDf(in_df, column_list, new_col)\n",
    "\n",
    "    # make dataframe bat nearest genes to peak\n",
    "\n",
    "    new_col = \"bat_nearest_gene\"\n",
    "    in_df = bat.copy()\n",
    "    column_list = list(in_df.columns[1:])\n",
    "    batm, batm_agg = makeCoorGeneDf(in_df, column_list, new_col)\n",
    "\n",
    "    # compute synteny\n",
    "    n, m, y, merged = computeSynteny(hum, batm)\n",
    "\n",
    "    out = os.path.join(os.path.split(\n",
    "        BAT)[0], \"NEAREST_MATCHED.\" + hu_ + \"_BAT_GENE.tsv\")\n",
    "    print(out)\n",
    "\n",
    "    # write the elements that match\n",
    "    getBatGenes(m, merged, out)\n",
    "\n",
    "    if len(y) > 0:\n",
    "        print(y)\n",
    "\n",
    "    # compute synteny (both upstream and downstream genes. \n",
    "    # DEMOTE - may be complicated by order of agg genes?)\n",
    "    # n_, m_, y_, merged_ = computeSynteny(hum_agg, batm_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2619cd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T16:34:05.334696Z",
     "start_time": "2023-07-18T16:34:05.289220Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hg38.coor</th>\n",
       "      <th>hu_nearest_gene</th>\n",
       "      <th>bat_nearest_gene</th>\n",
       "      <th>agree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1:909993-910631</td>\n",
       "      <td>OR4F16</td>\n",
       "      <td>SAMD11</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1:909993-910631</td>\n",
       "      <td>SAMD11</td>\n",
       "      <td>SAMD11</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1:911149-911448</td>\n",
       "      <td>OR4F16</td>\n",
       "      <td>SAMD11</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1:911149-911448</td>\n",
       "      <td>SAMD11</td>\n",
       "      <td>SAMD11</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1:912914-913272</td>\n",
       "      <td>OR4F16</td>\n",
       "      <td>SAMD11</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            hg38.coor hu_nearest_gene bat_nearest_gene  agree\n",
       "0  chr1:909993-910631         OR4F16            SAMD11  False\n",
       "1  chr1:909993-910631         SAMD11            SAMD11   True\n",
       "2  chr1:911149-911448         OR4F16            SAMD11  False\n",
       "3  chr1:911149-911448         SAMD11            SAMD11   True\n",
       "4  chr1:912914-913272         OR4F16            SAMD11  False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdae07e",
   "metadata": {},
   "source": [
    "## test one hg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7458c3fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T16:34:05.611844Z",
     "start_time": "2023-07-18T16:34:05.337620Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hg38.coor</th>\n",
       "      <th>gene_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>chr18:9121615-9121728</td>\n",
       "      <td>NDUFV2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>chr18:9121615-9121728</td>\n",
       "      <td>NDUFV2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>chr18:9090881-9091277</td>\n",
       "      <td>NDUFV2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>chr18:9082660-9083600</td>\n",
       "      <td>NDUFV2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>chr18:9073679-9074126</td>\n",
       "      <td>NDUFV2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210114</th>\n",
       "      <td>chr3:173396702-173396954</td>\n",
       "      <td>NLGN1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210115</th>\n",
       "      <td>chr3:173584161-173584470</td>\n",
       "      <td>NLGN1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210116</th>\n",
       "      <td>chr3:173584862-173585809</td>\n",
       "      <td>NLGN1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210117</th>\n",
       "      <td>chr3:173622121-173623020</td>\n",
       "      <td>NLGN1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210118</th>\n",
       "      <td>chr3:173688570-173689258</td>\n",
       "      <td>NLGN1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132889 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       hg38.coor gene_name\n",
       "14         chr18:9121615-9121728    NDUFV2\n",
       "15         chr18:9121615-9121728    NDUFV2\n",
       "16         chr18:9090881-9091277    NDUFV2\n",
       "17         chr18:9082660-9083600    NDUFV2\n",
       "18         chr18:9073679-9074126    NDUFV2\n",
       "...                          ...       ...\n",
       "210114  chr3:173396702-173396954     NLGN1\n",
       "210115  chr3:173584161-173584470     NLGN1\n",
       "210116  chr3:173584862-173585809     NLGN1\n",
       "210117  chr3:173622121-173623020     NLGN1\n",
       "210118  chr3:173688570-173689258     NLGN1\n",
       "\n",
       "[132889 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in bat\n",
    "bat.loc[bat[\"hg38.coor\"].isin(m)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d12e9cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T16:34:06.133320Z",
     "start_time": "2023-07-18T16:34:05.613990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      hg38.coor bat_nearest_gene\n",
      "25728  chr6:127518712-127519520            SOGA3 \n",
      "\n",
      "\n",
      "                       hg38.coor hu_nearest_gene\n",
      "154383  chr6:127518712-127519520          SOGA3 \n",
      "338743  chr6:127518712-127519520          SOGA3 \n",
      "                       hg38.coor           hu_nearest_genes   gene1    gene2\n",
      "154383  chr6:127518712-127519520  SOGA3 (-115), SOGA3 (+75)  SOGA3    SOGA3 \n",
      "                      hg38.coor gene_name\n",
      "25728  chr6:127518712-127519520     SOGA3\n"
     ]
    }
   ],
   "source": [
    "COOR = \"chr6:127518712-127519520\"\n",
    "print(batm.loc[batm[\"hg38.coor\"] ==COOR], '\\n\\n')\n",
    "\n",
    "print(hum.loc[hum[\"hg38.coor\"] ==COOR]), print(hu.loc[hu[\"hg38.coor\"] ==COOR]) \n",
    "print(bat.loc[bat[\"hg38.coor\"]==COOR])"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/slifong08/46f0c4f17ac1776c7fb2a239211ef091"
  },
  "gist": {
   "data": {
    "description": "other_analyses/for-wei_bats/3_GREAT_bat_synteny.ipynb",
    "public": true
   },
   "id": "46f0c4f17ac1776c7fb2a239211ef091"
  },
  "kernelspec": {
   "display_name": "Python (mamba)",
   "language": "python",
   "name": "mamba"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
