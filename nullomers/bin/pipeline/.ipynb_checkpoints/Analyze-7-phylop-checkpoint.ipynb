{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06063260",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# 20221129\n",
    "# \n",
    "# sarahfong\n",
    "# \n",
    "# ### intersect nullomers, empirical shuffle with phylop 100way bigWig\n",
    "# \n",
    "# split by exonic/non-exonic\n",
    "# \n",
    "# \n",
    "# use bigWigSummary executable from UCSC to get phylop \n",
    "# \n",
    "# \n",
    "# compare nullomers v. empirical background\n",
    "\n",
    "# In[ ]:\n",
    "â€”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73d48f81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T02:01:54.547859Z",
     "start_time": "2023-01-16T02:01:52.164013Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "import pybedtools as pbt\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import statsmodels as sm\n",
    "\n",
    "# append path\n",
    "sys.path.append(\"/wynton/home/ahituv/fongsl/tools/py_/\")\n",
    "\n",
    "# import config reader\n",
    "import config_readwrite as crw\n",
    "import zippery\n",
    "\n",
    "\n",
    "\n",
    "config_tag = \"config-exon.ini\"\n",
    "\n",
    "# append path\n",
    "sys.path.append(\"/wynton/home/ahituv/fongsl/tools/py_/\")\n",
    "\n",
    "# import config reader\n",
    "import config_readwrite as crw\n",
    "import count_lines as cl\n",
    "import plot_params as pp\n",
    "\n",
    "config_name = os.path.join(os.getcwd(), config_tag)\n",
    "\n",
    "config, configname = crw.read_config(config_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c72435",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fce9800b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T02:01:54.558676Z",
     "start_time": "2023-01-16T02:01:54.551222Z"
    }
   },
   "outputs": [],
   "source": [
    "DATASET = \"PHYLOP\"\n",
    "\n",
    "DATA_PATH = config[DATASET][\"PATH\"]\n",
    "RE_PATH = config[\"RESULTS\"][\"PATH\"] \n",
    "\n",
    "ANNOT = config[\"GENCODE\"][\"ANNOT\"] \n",
    "\n",
    "RE = os.path.join(RE_PATH, DATASET)\n",
    "\n",
    "if os.path.exists(RE) is False:\n",
    "    os.mkdir(RE)\n",
    "    config[\"RESULTS\"][DATASET] = RE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00011877",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8027e220",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T02:01:57.114783Z",
     "start_time": "2023-01-16T02:01:57.088473Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_lines(df, out_pdf,datatype, xrange):\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    sns.lineplot(df, x=\"pos\", y= '50%', hue = \"label\" )\n",
    "    sns.lineplot(df, x=\"pos\", y= '25%', hue = \"label\")\n",
    "    sns.lineplot(df, x=\"pos\", y= '75%', hue = \"label\")\n",
    "\n",
    "    ax.axvline(499, color=\"grey\", ls = \"--\") # center line\n",
    "    \n",
    "    ax.set(xlim = (xrange[0], xrange[1]),\n",
    "           ylabel = \"phylop score - 100way\",\n",
    "            title = f\"{datatype}:{xrange[0]}-{xrange[1]}\")\n",
    "    \n",
    "    ax.legend(loc=\"upper right\")\n",
    "    \n",
    "    plt.savefig(out_pdf, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_line(y, df, out_pdf,datatype, xrange):\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    sns.lineplot(df, x=\"pos\", y=y, hue=\"label\")\n",
    "    \n",
    "    ax.axvline(499, color=\"grey\", ls = \"--\") # center line\n",
    "    \n",
    "    ax.set(xlim = (xrange[0], xrange[1]),\n",
    "           ylabel = f\"phylop score - 100way-{y}\",\n",
    "            title = f\"{datatype}:{xrange[0]}-{xrange[1]}\")\n",
    "    \n",
    "    ax.legend(loc=\"upper right\")\n",
    "    \n",
    "    plt.savefig(out_pdf, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def calculateEmpiricalP(obs, exp_sum_list):\n",
    "    \n",
    "    import datetime\n",
    "    \"\"\"\n",
    "    return two lists\n",
    "        (1) info - vector w/  \n",
    "                n_obs, \n",
    "                median_exp, \n",
    "                std, \n",
    "                fold-change  # calculated from the median of expected shuffle \n",
    "                p_val\n",
    "                \n",
    "        (2) fold_changes- vector expected fold changes (to calculate confidence interval)\n",
    "        \n",
    "    input\n",
    "        observed overlap count (int)\n",
    "        list of expected overlap counts (list of ints)\n",
    "    \n",
    "    method\n",
    "        1. get median of expected overlap counts\n",
    "        2. get standard deviation of expected overlap counts\n",
    "        3. center expected overlap counts at median\n",
    "        4. Sum the number of centered expected counts greater than observed centered count\n",
    "            This is two tailed because it evaluates both sides of the distribution (w/ abs value). \n",
    "        5. calculate fold change as observed/ median expected w/ pseudo count\n",
    "        6. calculate fold change of each \"obs\"/ expected w/ pseudo count\n",
    "        7. calculate the p-value as count of equal or more extreme values than observed value\n",
    "        8. return list of empirical info + fold changes\n",
    "        \n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "    #1\n",
    "    mu = np.median(exp_sum_list)  # median of exp.dist\n",
    "    \n",
    "    #2\n",
    "    sigma = np.std(exp_sum_list)  # std\n",
    "    \n",
    "    #3\n",
    "    dist_from_mu = [exp - mu for exp in exp_sum_list] # center the distribution \n",
    "    \n",
    "    #4\n",
    "    p_sum = sum(1 for exp_dist in dist_from_mu if abs(exp_dist) >= abs(obs - mu)) # count values >= centered obs\n",
    "\n",
    "    #5\n",
    "    fold_change = (obs + 1.0) / (mu + 1.0) # fold change obs from median expected w pseudo count\n",
    "    \n",
    "    #6\n",
    "    fold_changes = list((obs + 1.0) / (m + 1.0) for m in exp_sum_list) # fold change obs from /each exp w pseudo count\n",
    "    \n",
    "    #7\n",
    "    p_val = (p_sum + 1.0) / (len(exp_sum_list) + 1.0)  # probability of observing obs-like value equal or more extreme in expected distribution\n",
    "    \n",
    "    #8\n",
    "    info = [\n",
    "            obs, \n",
    "            mu, \n",
    "            sigma, \n",
    "            fold_change, \n",
    "            p_val, \n",
    "            str(datetime.datetime.now())\n",
    "            ]\n",
    "    \n",
    "    return info, fold_changes\n",
    "\n",
    "def exp(nullo, shuf, summary_stat_name, pos):\n",
    "    \"\"\"\n",
    "    return PER POSITION foldchange, empirical P between observed and expected (shuffled) data\n",
    "    \n",
    "    input\n",
    "        nullo (df) - pandas dataframe of nullomer summary stats in long form (each row is one base in dist)\n",
    "        shuf (df) - pandas dataframe of N shuffled summary stats in long form (each row is one base in dist)\n",
    "        summary_stat_name (str) - summary_stat measurement name (this should be a column in the dataframes)\n",
    "        pos (int) - relative position of the base to estimate fold change between. \n",
    "        \n",
    "    method\n",
    "        1. prepare position phylop vectors for obs, exp\n",
    "        2. calculate empirical P\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    obs = nullo.loc[nullo[\"pos\"]== pos, summary_stat_name].iloc[0]\n",
    "    exp_list =  shuf.loc[shuf[\"pos\"]== pos, summary_stat_name].to_list()\n",
    "    \n",
    "    info, fold_changes = calculateEmpiricalP(obs, exp_list)\n",
    "    \n",
    "    print(info)\n",
    "    \n",
    "    return info, fold_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "435dbcd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T02:02:24.642363Z",
     "start_time": "2023-01-16T02:02:24.635683Z"
    }
   },
   "outputs": [],
   "source": [
    "def formatDf(datatype, query):\n",
    "    \"\"\"\n",
    "    glob all query files for datatype and turn these data into a single dataframe\n",
    "    split dataframe based on nullomer v shuffle\n",
    "    \n",
    "    input \n",
    "        datatype (str) - label for dataset (e.g. exon-overlpa, no exon-overlap)\n",
    "        query (str) - fragment of str to glob files on. \n",
    "        \n",
    "    method\n",
    "        1. glob all files\n",
    "        2. make a list to collect pandas dataframes\n",
    "        3. assign LABEL - NULLOMER/SHUF  for each dataset. \n",
    "        4. assign ID - str of the file name\n",
    "        5. open the file as a pandas dataframe, add label, id columns, append to collection list\n",
    "        6. concatenate all dataframes together\n",
    "        7. split dataframes on NULLOMER/SHUF label\n",
    "        \n",
    "    return \n",
    "        df (pd dataframe) - all data\n",
    "        nullo (pd dataframe) - data for just nullomers\n",
    "        shuf (pd dataframe) - data for just matched shuffles\n",
    "        \n",
    "    \"\"\"\n",
    "    #1\n",
    "    file_list = glob.glob(os.path.join(DATA_PATH, query))\n",
    "    print(len(file_list))\n",
    "    \n",
    "    #2\n",
    "    df_list = []\n",
    "    \n",
    "    #3\n",
    "    for f in file_list:\n",
    "    \n",
    "        # assign static label\n",
    "        if \"shuf\" in f:\n",
    "            LABEL = f\"SHUF-{datatype}\"\n",
    "        else:\n",
    "            LABEL = datatype\n",
    "        #4\n",
    "        ID = f.split(\"/\")[-1]\n",
    "        \n",
    "        #5\n",
    "        df = pd.read_csv(f, sep='\\t')\n",
    "        \n",
    "        df[\"label\"], df[\"id\"] = LABEL, ID\n",
    "\n",
    "        df_list.append(df)    \n",
    "    #6\n",
    "    df = pd.concat(df_list)\n",
    "    \n",
    "    #7\n",
    "    nullo = df.loc[df[\"label\"] == datatype]\n",
    "    shuf = df.loc[df[\"label\"] != datatype]\n",
    "\n",
    "    return df, nullo, shuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "020a6fc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T02:02:25.989424Z",
     "start_time": "2023-01-16T02:02:25.983677Z"
    }
   },
   "outputs": [],
   "source": [
    "def center_stats(nullo, shuf):\n",
    "    \"\"\"\n",
    "    print obs v. exp at center position stats w/ median values\n",
    "    \"\"\"\n",
    "    \n",
    "    # MIDPOINT - median summary stats \n",
    "    i, f = exp(nullo, shuf, \"50%\", 500)\n",
    "\n",
    "    # MIDPOINT-100 - median summary stats \n",
    "    i, f = exp(nullo, shuf, \"50%\", 400)\n",
    "\n",
    "    # MIDPOINT+100 - median summary stats \n",
    "    i, f = exp(nullo, shuf, \"50%\", 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4278178",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T02:03:27.181187Z",
     "start_time": "2023-01-16T02:02:33.989183Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXON-OVERLAP\n",
      "501\n"
     ]
    }
   ],
   "source": [
    "SETS = [('EXON-OVERLAP', \"*-exon_overlap*SUMMARY_STATS.txt\"), \n",
    "       (\"EXON-NO-OVERLAP\", \"*-exon_no-overlap*SUMMARY_STATS.txt\")]\n",
    "\n",
    "lines = []  # for collecting stats\n",
    "for DATATYPE, QUERY in SETS:\n",
    "    print(DATATYPE)\n",
    "    df, nullo, shuf = formatDf(DATATYPE, QUERY)\n",
    "    break\n",
    "    ## plot each percentile + xranges \n",
    "\n",
    "    ys = [\"25%\", \"50%\", \"75%\"]\n",
    "    ranges = [(\"1kb\", [0,1000]), (\"0.2kb\", [400, 600]),  (\"0.1kb\", [450,550])]\n",
    "    \n",
    "    for y in ys:\n",
    "        for name, xrange in ranges:\n",
    "            out = os.path.join(RE, f\"phylop-{name}_{ANNOT}_{DATATYPE}-{y}.pdf\")\n",
    "            plot_line(y, df, out, DATATYPE, xrange)\n",
    "\n",
    "    ## plot counts of phylop values\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    sns.lineplot(df, x=\"pos\", y= 'count', hue = \"label\")\n",
    "    ax.set(title = DATATYPE)\n",
    "    out = os.path.join(RE, f\"{DATATYPE}-count.pdf\")\n",
    "    plt.savefig(out)\n",
    "\n",
    "    ## plot everything together\n",
    "\n",
    "    for name, xrange in ranges:\n",
    "        out = os.path.join(RE, f\"phylop-{name}_{ANNOT}_{DATATYPE}.pdf\")\n",
    "\n",
    "        plot_lines(df, out, DATATYPE, xrange)\n",
    "        \n",
    "    ### empirical P for median phylop\n",
    "    # MIDPOINT - median summary stats \n",
    "\n",
    "    center_stats(nullo, shuf)\n",
    "    for pos in np.arange(0,1000):\n",
    "        \"\"\"\n",
    "        collect obs v exp stats\n",
    "        \"\"\"\n",
    "        i, f = exp(nullo, shuf, \"50%\", pos)\n",
    "\n",
    "        i.extend([pos,f\"{ANNOT}-{DATATYPE}\", \"50%\\n\"])\n",
    "        i = [str(item) for item in i]\n",
    "        line = \"\\t\".join(i)\n",
    "        lines.append(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f24912",
   "metadata": {},
   "source": [
    "# write all the stats to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54c7c5ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T23:23:55.741188Z",
     "start_time": "2022-12-21T23:23:55.628329Z"
    }
   },
   "outputs": [],
   "source": [
    " out_stat=os.path.join(RE, f\"{DATASET}_{ANNOT}_empirical-stats.txt\")\n",
    "\n",
    "with open(out_stat, \"w\") as writer:\n",
    "    for line in lines:\n",
    "        writer.write(line)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4958f16c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
