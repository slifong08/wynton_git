{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to train DeepSTARR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Used packages and their version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GPU environment \n",
    "\n",
    "# conda create --name DeepSTARR python=3.7 tensorflow-gpu=1.14.0 keras-gpu=2.2.4\n",
    "# conda activate DeepSTARR\n",
    "# conda install numpy=1.16.2 pandas=0.25.3 matplotlib=3.1.1 ipykernel=5.4.3\n",
    "# pip install git+git://github.com/AvantiShri/shap.git@master\n",
    "# pip install 'h5py<3.0.0'\n",
    "# pip install deeplift==0.6.13.0\n",
    "# pip install keras-tuner==1.0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T22:34:33.468198Z",
     "start_time": "2024-02-22T22:33:13.979887Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/wynton/home/ahituv/fongsl/micromamba/envs/DeepSTARR/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/wynton/home/ahituv/fongsl/micromamba/envs/DeepSTARR/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/wynton/home/ahituv/fongsl/micromamba/envs/DeepSTARR/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/wynton/home/ahituv/fongsl/micromamba/envs/DeepSTARR/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/wynton/home/ahituv/fongsl/micromamba/envs/DeepSTARR/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/wynton/home/ahituv/fongsl/micromamba/envs/DeepSTARR/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/wynton/home/ahituv/fongsl/micromamba/envs/DeepSTARR/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/wynton/home/ahituv/fongsl/micromamba/envs/DeepSTARR/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/wynton/home/ahituv/fongsl/micromamba/envs/DeepSTARR/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/wynton/home/ahituv/fongsl/micromamba/envs/DeepSTARR/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/wynton/home/ahituv/fongsl/micromamba/envs/DeepSTARR/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/wynton/home/ahituv/fongsl/micromamba/envs/DeepSTARR/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "import keras.layers as kl\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers.core import Dropout, Reshape, Dense, Activation, Flatten\n",
    "from keras.layers import BatchNormalization, InputLayer, Input\n",
    "from keras import models\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, History, ModelCheckpoint\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys, os\n",
    "#sys.path.append('Neural_Network_DNA_Demo/')\n",
    "#from helper # from https://github.com/const-ae/Neural_Network_DNA_Demo\n",
    "import IOHelper, SequenceHelper \n",
    "\n",
    "import random\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# FASTA files with DNA sequences of genomic regions from train/val/test sets\n",
    "!wget 'https://data.starklab.org/almeida/DeepSTARR/Data/Sequences_Train.fa'\n",
    "!wget 'https://data.starklab.org/almeida/DeepSTARR/Data/Sequences_Val.fa'\n",
    "!wget 'https://data.starklab.org/almeida/DeepSTARR/Data/Sequences_Test.fa'\n",
    "\n",
    "# Files with USelopmental and housekeeping activity of genomic regions from train/val/test sets\n",
    "!wget 'https://data.starklab.org/almeida/DeepSTARR/Data/Sequences_activity_Train.txt'\n",
    "!wget 'https://data.starklab.org/almeida/DeepSTARR/Data/Sequences_activity_Val.txt'\n",
    "!wget 'https://data.starklab.org/almeida/DeepSTARR/Data/Sequences_activity_Test.txt'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T22:36:17.144887Z",
     "start_time": "2024-02-22T22:36:17.140091Z"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'class.all'\n",
    "data_path = \"/wynton/home/ahituv/fongsl/EMF/US/ml_emf/data/deepstarr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T22:36:19.478996Z",
     "start_time": "2024-02-22T22:36:18.917545Z"
    }
   },
   "outputs": [],
   "source": [
    "# SF add\n",
    "#prefix = sys.argv[1] # dataset to pull  \n",
    "#data_path = sys.argv[2]\n",
    "\n",
    "model_name=\"DeepSTARR_ATAC\"\n",
    "params = {'batch_size': 128,\n",
    "          'epochs': 50, # 100\n",
    "          'early_stop': 10,\n",
    "          'kernel_size1': 7,\n",
    "          'kernel_size2': 3,\n",
    "          'kernel_size3': 5,\n",
    "          'kernel_size4': 3,\n",
    "          'lr': 0.002,\n",
    "          'num_filters': 256,\n",
    "          'num_filters2': 60,\n",
    "          'num_filters3': 60,\n",
    "          'num_filters4': 120,\n",
    "          'n_conv_layer': 4,\n",
    "          'n_add_layer': 2,\n",
    "          'dropout_prob': 0.4,\n",
    "          'dense_neurons1': 256,\n",
    "          'dense_neurons2': 256,\n",
    "          'pad':'same', \n",
    "          \"n_nucleotides\":4, \n",
    "          \"seq_len\":271,\n",
    "          \"pred_task\":\"class\" # or regression\n",
    "         }\n",
    "\n",
    "# SF add params to paramdict\n",
    "params[\"prefix\"] = prefix\n",
    "params[\"data_path\"]=data_path\n",
    "\n",
    "# SF add change directory\n",
    "os.chdir(data_path)\n",
    "\n",
    "\n",
    "# function to load sequences and enhancer activity\n",
    "def prepare_input(set):\n",
    "    # Convert sequences to one-hot encoding matrix\n",
    "    file_seq = str(f\"{prefix}.Sequences_\" + set + \".fa\")\n",
    "    input_fasta_data_A = IOHelper.get_fastas_from_file(file_seq, uppercase=True)\n",
    "\n",
    "    # get length of first sequence\n",
    "    sequence_length = len(input_fasta_data_A.sequence.iloc[0])\n",
    "\n",
    "    # Convert sequence to one hot encoding matrix\n",
    "    seq_matrix_A = SequenceHelper.do_one_hot_encoding(input_fasta_data_A.sequence, sequence_length,\n",
    "                                                      SequenceHelper.parse_alpha_to_seq)\n",
    "    print(seq_matrix_A.shape)\n",
    "    \n",
    "    X = np.nan_to_num(seq_matrix_A) # Replace NaN with zero and infinity with large finite numbers\n",
    "    X_reshaped = X.reshape((X.shape[0], X.shape[1], X.shape[2]))\n",
    "\n",
    "    Activity = pd.read_table(f\"{prefix}.Sequences_activity_\" + set + \".txt\")\n",
    "    Y_dev = Activity.US\n",
    "    Y_hk = Activity.ctrl\n",
    "    Y = [Y_dev, Y_hk]\n",
    "    \n",
    "    print(set)\n",
    "\n",
    "    return input_fasta_data_A.sequence, seq_matrix_A, X_reshaped, Y\n",
    "\n",
    "### Additional metrics\n",
    "\n",
    "def Spearman(y_true, y_pred):\n",
    "     return ( tf.py_function(spearmanr, [tf.cast(y_pred, tf.float32), \n",
    "                       tf.cast(y_true, tf.float32)], Tout = tf.float32) )\n",
    "\n",
    "    \n",
    "def train(selected_model, X_train, Y_train, X_valid, Y_valid, params):\n",
    "\n",
    "    my_history=selected_model.fit(X_train, Y_train,\n",
    "                                  validation_data=(X_valid, Y_valid),\n",
    "                                  batch_size=params['batch_size'], epochs=params['epochs'],\n",
    "                                  callbacks=[EarlyStopping(patience=params['early_stop'], monitor=\"val_loss\", restore_best_weights=True),\n",
    "                                             History()])\n",
    "    \n",
    "    return selected_model, my_history\n",
    "    \n",
    "\n",
    "\n",
    "# create functions\n",
    "def summary_statistics(X, Y, set, task):\n",
    "    pred = main_model.predict(X, batch_size=main_params['batch_size'])\n",
    "    if task ==\"US\":\n",
    "        i=0\n",
    "    if task ==\"ctrl\":\n",
    "        i=1\n",
    "        \n",
    "    if main_params['pred_task'] == \"linear\":\n",
    "        print(set + ' MSE ' + task + ' = ' + str(\"{0:0.2f}\".format(mean_squared_error(Y[i], pred[i].squeeze()))))\n",
    "        print(set + ' PCC ' + task + ' = ' + str(\"{0:0.2f}\".format(stats.pearsonr(Y[i], pred[i].squeeze())[0])))\n",
    "        print(set + ' SCC ' + task + ' = ' + str(\"{0:0.2f}\".format(stats.spearmanr(Y[i], pred[i].squeeze())[0])))\n",
    "    else:\n",
    "        \n",
    "        print(set, \"accuracy\" + task + \" = \" + str(\"{0:0.2f}\".format(accuracy_score(Y[i], pred[i].squeeze()))))\n",
    "        print(set, \"f1\" + task + \" = \" + str(\"{0:0.2f}\".format(f1_score(Y[i], pred[i].squeeze()))))\n",
    "\n",
    "    return pred[i]\n",
    "\n",
    "def DeepSTARR(params=params):\n",
    "    \n",
    "    lr = params['lr']\n",
    "    dropout_prob = params['dropout_prob']\n",
    "    n_conv_layer = params['n_conv_layer']\n",
    "    n_add_layer = params['n_add_layer']\n",
    "    \n",
    "    # body\n",
    "    input = kl.Input(shape=(params['seq_len'], params['n_nucleotides']))\n",
    "    x = kl.Conv1D(params['num_filters'], kernel_size=params['kernel_size1'],\n",
    "                  padding=params['pad'],\n",
    "                  name='Conv1D_1st')(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "\n",
    "    for i in range(1, n_conv_layer):\n",
    "        x = kl.Conv1D(params['num_filters'+str(i+1)],\n",
    "                      kernel_size=params['kernel_size'+str(i+1)],\n",
    "                      padding=params['pad'],\n",
    "                      name=str('Conv1D_'+str(i+1)))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling1D(2)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    # dense layers\n",
    "    for i in range(0, n_add_layer):\n",
    "        x = kl.Dense(params['dense_neurons'+str(i+1)],\n",
    "                     name=str('Dense_'+str(i+1)))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "    bottleneck = x\n",
    "    \n",
    "    # heads per task (developmental and housekeeping enhancer activities)\n",
    "    \n",
    "    # SF added below. Accommodate linear and classification tasks.\n",
    "    pred_task = params[\"pred_task\"] \n",
    "    \n",
    "    if pred_task == \"linear\":\n",
    "        activation_ = pred_task\n",
    "        loss_ = [\"mse\", \"mse\"]\n",
    "        metrics_ = Spearman\n",
    "        \n",
    "    elif pred_task == \"class\":\n",
    "        activation_ = tf.nn.softmax\n",
    "        loss_ = ['binary_crossentropy', 'binary_crossentropy']\n",
    "        metrics_ = 'accuracy'\n",
    "        \n",
    "    # end SF additions\n",
    "    \n",
    "    tasks = ['US', 'ctrl']\n",
    "    outputs = []\n",
    "    for task in tasks:\n",
    "        outputs.append(kl.Dense(1, activation=activation_, name=str('Dense_' + task))(bottleneck))  # changed activation=\"linear\"\n",
    "\n",
    "    model = keras.models.Model([input], outputs)\n",
    "    model.compile(keras.optimizers.Adam(lr=lr),\n",
    "                  loss = loss_,  # SF changed loss=['mse', 'mse'], # loss\n",
    "                  loss_weights=[1, 1], # loss weigths to balance\n",
    "                  metrics=[metrics_]) # additional track metric\n",
    "\n",
    "    return model, params\n",
    "\n",
    "\n",
    "### MAIN ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T22:36:32.194281Z",
     "start_time": "2024-02-22T22:36:31.831880Z"
    }
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 620. MiB for an array with shape (75019, 271, 4) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/scratch/fongsl/ipykernel_2614742/3799932094.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Data for train/val/test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_seq_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_valid_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid_seq_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Val\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_test_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_seq_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/fongsl/ipykernel_2614742/1534479274.py\u001b[0m in \u001b[0;36mprepare_input\u001b[0;34m(set)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# Convert sequence to one hot encoding matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     seq_matrix_A = SequenceHelper.do_one_hot_encoding(input_fasta_data_A.sequence, sequence_length,\n\u001b[0;32m---> 48\u001b[0;31m                                                       SequenceHelper.parse_alpha_to_seq)\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_matrix_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/EMF/US/ml_emf/bin/classifier/SequenceHelper.py\u001b[0m in \u001b[0;36mdo_one_hot_encoding\u001b[0;34m(sequence, seq_length, f)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdo_one_hot_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_alpha_to_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 620. MiB for an array with shape (75019, 271, 4) and data type float64"
     ]
    }
   ],
   "source": [
    "# Data for train/val/test sets\n",
    "X_train_sequence, X_train_seq_matrix, X_train, Y_train = prepare_input(\"Train\")\n",
    "X_valid_sequence, X_valid_seq_matrix, X_valid, Y_valid = prepare_input(\"Val\")\n",
    "X_test_sequence, X_test_seq_matrix, X_test, Y_test = prepare_input(\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T22:36:19.478996Z",
     "start_time": "2024-02-22T22:36:18.917545Z"
    }
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 620. MiB for an array with shape (75019, 271, 4) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/scratch/fongsl/ipykernel_2614742/1534479274.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;31m# Data for train/val/test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m \u001b[0mX_train_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_seq_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0mX_valid_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid_seq_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Val\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0mX_test_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_seq_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/fongsl/ipykernel_2614742/1534479274.py\u001b[0m in \u001b[0;36mprepare_input\u001b[0;34m(set)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# Convert sequence to one hot encoding matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     seq_matrix_A = SequenceHelper.do_one_hot_encoding(input_fasta_data_A.sequence, sequence_length,\n\u001b[0;32m---> 48\u001b[0;31m                                                       SequenceHelper.parse_alpha_to_seq)\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_matrix_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/EMF/US/ml_emf/bin/classifier/SequenceHelper.py\u001b[0m in \u001b[0;36mdo_one_hot_encoding\u001b[0;34m(sequence, seq_length, f)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdo_one_hot_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_alpha_to_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 620. MiB for an array with shape (75019, 271, 4) and data type float64"
     ]
    }
   ],
   "source": [
    "DeepSTARR()[0].summary()\n",
    "DeepSTARR()[1] # dictionary\n",
    "\n",
    "main_model, main_params = DeepSTARR()\n",
    "main_model, my_history = train(main_model, X_train, Y_train, X_valid, Y_valid, main_params)\n",
    "\n",
    "# run for each set and enhancer type\n",
    "train_us_pred = summary_statistics(X_train, Y_train[0], \"train\", \"US\")\n",
    "train_ctrl_pred = summary_statistics(X_train, Y_train[1], \"train\", \"ctrl\")\n",
    "val_us_pred = summary_statistics(X_valid, Y_valid[0], \"validation\", \"US\")\n",
    "val_ctrl_pred = summary_statistics(X_valid, Y_valid[1], \"validation\", \"ctrl\")\n",
    "test_us_pred = summary_statistics(X_test, Y_test[0], \"test\", \"US\")\n",
    "test_ctrl_pred = summary_statistics(X_test, Y_test[1], \"test\", \"ctrl\")\n",
    "\n",
    "preds = pd.merge(pd.DataFrame(test_us_pred), pd.DataFrame(test_ctrl_pred), left_index=True, right_index=True)\n",
    "preds.columns = [\"pred_US\", \"pred_ctrl\"]\n",
    "\n",
    "# write actual and predicted values to file\n",
    "pd.merge(pd.DataFrame(Y_test).T, preds, left_index=True, right_index=True).to_csv(f\"{model_name}.preds.tsv\", sep='\\t', index=False)\n",
    "\n",
    "\n",
    "# write model\n",
    "\n",
    "## config\n",
    "model_json = main_model.to_json()\n",
    "with open(f'Model_{model_name}.{prefix}.json', \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "### weights \n",
    "main_model.save_weights(f'Model_{model_name}.{prefix}.h5')\n",
    "\n",
    "# write params # SF added\n",
    "\n",
    "with open(f'config' + model_name + f'.{prefix}.json', \"w\") as json_file:\n",
    "    for key, value in params.items():\n",
    "        json_file.write(f\"{key}:{value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write params # SF added\n",
    "\n",
    "with open(f'config' + model_name + f'.{prefix}.json', \"w\") as json_file:\n",
    "    for key, value in params.items():\n",
    "        json_file.write(f\"{key}:{value}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"DeepSTARR_ATAC\"\n",
    "\n",
    "# write model\n",
    "model_json = main_model.to_json()\n",
    "with open(f'Model_' + model_name + f'.{prefix}.json', \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "main_model.save_weights('Model_' + model_name + '.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T23:44:27.110880Z",
     "start_time": "2024-02-21T23:44:24.644084Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.JointGrid at 0x7fe31c373650>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAJOCAYAAACqbjP2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAoSklEQVR4nO3de3BW9Z3A/09CIICY+EMgBLmIVkRqRQ3ecB1viKKD092tumt3UYsVRisq6g7Uqtj1t2y7W7whahWk7k8tq1VWZ/HCjBXxuoLQqmhtFQ3WAMZLEi5GA+f3h0u2KUi/eUzyhOT1mnlmeU7OyfPJd1PO2/OchIIsy7IAAGCnCvM9AADArkA0AQAkEE0AAAlEEwBAAtEEAJBANAEAJBBNAAAJRBMAQALRBACQQDQBACQQTQAACUQTAECConwPAABtobKyMqqrq9vs9fr06RODBw9us9ej9YkmADq8ysrKGD78gNi8eVObvWaPHj3jzTffEE4diGgCoMOrrq6OzZs3xRHfuzZKyvdu9derrXo3Xpp3XVRXV4umDkQ0AdBplJTvHb0H75/vMdhFuREcACCBaAIASCCaAAASiCYAgASiCQAggWgCAEggmgAAEogmAIAEogkAIIFoAgBIIJoAABKIJgCABKIJACCBaAIASCCaAAASiCYAgASiCQAggWgCAEggmgAAEogmAIAEogkAIIFoAgBIIJoAABKIJgCABKIJACCBaAIASCCaAAASiCYAgASiCQAggWgCAEggmgAAEogmAIAEogkAIIFoAgBIIJoAABKIJgCABEX5HqAjqKysjOrq6jZ7vT59+sTgwYPb7PUAANH0tVVWVsbw4QfE5s2b2uw1e/ToGW+++YZwAoA2JJq+purq6ti8eVMc8b1ro6R871Z/vdqqd+OleddFdXW1aAKANiSaWkhJ+d7Re/D++R4DAGglbgQHAEggmgAAEogmAIAEogkAIIFoAgBIIJoAABKIJgCABKIJACCBaAIASCCaAAASiCYAgASiCQAggWgCAEggmgAAEogmAIAEogkAIIFoAgBIIJoAABKIJgCABKIJACCBaAIASCCaAAASiCYAgASiCQAggWgCAEggmgAAEogmAIAERfkeIB+yLIu6uroW+VwbNmyIiIiP3/tdNNRvbpHPuTO1aysjImL58uWNr93aCgsLY+vWrW3yWl5v130tr+f12vPr/e53v4uItv+7esOGDVFbW9sin3P33XePgoKCFvlc5KYgy7Is30O0tdra2igtLc33GACQrKamJkpKSvI9RqfWKaOpJa801dbWxqBBg2LNmjW+mZvBuuXGuuXGuuXGuuWuNdbOlab865RvzxUUFLT4XwAlJSX+UsmBdcuNdcuNdcuNdcudtetY3AgOAJBANAEAJBBNX1NxcXFce+21UVxcnO9RdinWLTfWLTfWLTfWLXfWrmPqlDeCAwA0lytNAAAJRBMAQALRBACQQDQBACQQTQAACUQTAEAC0QQAkKBTRlOWZVFbWxt+RRUAHZnzXcvqlNFUV1cXpaWlUVdXl+9RAKDVON+1rE4ZTQAAzSWaAAASiCYAgASiCQAggWgCAEggmgAAEogmAIAEogkAIIFoAgBIIJoAABKIJgCABKIJACCBaAIASCCaAAASiCYAgASiCQAggWgCAEggmgAAEhTlewAAoHWtXLkyevXqle8x2pU+ffrE4MGDm3WMaAKADu7YY4/N9wjtTo8ePePNN99oVjiJJgDo4Cr+YVr0HrJ/vsdoN2qr3o2X5l0X1dXVogkA+D8l/QdH78Gi6etyIzgAQALRBACQQDQBACQQTQAACUQTAEAC0QQAkEA0AQAkEE0AAAlEEwBAAtEEAJBANAEAJBBNAAAJRBMAQALRBACQQDQBACQQTQAACUQTAEAC0QQAkEA0AQAkEE0AAAlEEwBAAtEEAJBANAEAJBBNAAAJRBMAQALRBACQQDQBACQQTQAACUQTAEAC0QQAkEA0AQAkEE0AAAnyGk3PPPNMjB8/PgYMGBAFBQWxcOHC5GOfe+65KCoqioMPPrjV5gMA2Cav0bRx48YYOXJkzJ49u1nH1dTUxIQJE+LEE09spckAAJoqyueLjxs3LsaNG9fs4yZNmhRnn312dOnSpVlXpwAAcrXL3dN09913x9tvvx3XXnttvkcBADqRvF5paq7f//73MW3atFi6dGkUFaWPXl9fH/X19Y3Pa2trW2M8AMgr57vWtctcadqyZUucffbZcd1118WwYcOadezMmTOjtLS08TFo0KBWmhIA8sf5rnXtMtFUV1cXy5Ytix/84AdRVFQURUVF8eMf/zh+85vfRFFRUTz11FNfeez06dOjpqam8bFmzZo2nBwA2obzXevaZd6eKykpiVdffbXJtjlz5sRTTz0VDz74YAwdOvQrjy0uLo7i4uLWHhEA8sr5rnXlNZo2bNgQf/jDHxqfr169OlauXBm9e/eOwYMHx/Tp0+OPf/xj3HPPPVFYWBgHHnhgk+P79esX3bt33247AEBLy2s0LVu2LI4//vjG51OnTo2IiHPOOSfmz58fVVVVUVlZma/xAAAa5TWajjvuuMiy7Cs/Pn/+/J0eP2PGjJgxY0bLDgUAsAO7zI3gAAD5JJoAABKIJgCABKIJACCBaAIASCCaAAASiCYAgASiCQAggWgCAEggmgAAEogmAIAEogkAIIFoAgBIIJoAABKIJgCABKIJACCBaAIASCCaAAASiCYAgASiCQAggWgCAEggmgAAEogmAIAEogkAIIFoAgBIIJoAABKIJgCABKIJACCBaAIASCCaAAASiCYAgASiCQAggWgCAEggmgAAEogmAIAEogkAIIFoAgBIIJoAABKIJgCABKIJACCBaAIASCCaAAASiCYAgASiCQAggWgCAEggmgAAEogmAIAEogkAIIFoAgBIIJoAABKIJgCABKIJACCBaAIASCCaAAASiCYAgASiCQAggWgCAEggmgAAEogmAIAEogkAIIFoAgBIIJoAABKIJgCABKIJACCBaAIASCCaAAASiCYAgASiCQAggWgCAEiQ12h65plnYvz48TFgwIAoKCiIhQsX7nT/hx56KE466aTo27dvlJSUxFFHHRVPPPFE2wwLAHRqeY2mjRs3xsiRI2P27NlJ+z/zzDNx0kknxaJFi2L58uVx/PHHx/jx42PFihWtPCkA0NkV5fPFx40bF+PGjUve/8Ybb2zy/F/+5V/iv/7rv+LRRx+NQw45pIWnAwD4P3mNpq9r69atUVdXF717997pfvX19VFfX9/4vLa2trVHA4A253zXunbpG8F/9rOfxcaNG+PMM8/c6X4zZ86M0tLSxsegQYPaaEIAaDvOd61rl42m+++/P2bMmBELFiyIfv367XTf6dOnR01NTeNjzZo1bTQlALQd57vWtUu+PbdgwYKYOHFiPPDAAzFmzJi/uH9xcXEUFxe3wWQAkD/Od61rl7vSdP/998e5554b9913X5x22mn5HgcA6CTyeqVpw4YN8Yc//KHx+erVq2PlypXRu3fvGDx4cEyfPj3++Mc/xj333BMRXwbThAkT4qabboojjzwy1q5dGxERPXr0iNLS0rx8DQBA55DXK03Lli2LQw45pPHXBUydOjUOOeSQuOaaayIioqqqKiorKxv3v+OOO6KhoSEuuuiiKC8vb3xccskleZkfAOg88nql6bjjjossy77y4/Pnz2/y/Omnn27dgQAAvsIud08TAEA+iCYAgASiCQAggWgCAEggmgAAEogmAIAEogkAIIFoAgBIIJoAABKIJgCABKIJACCBaAIASCCaAAASiCYAgASiCQAggWgCAEggmgAAEogmAIAEogkAIIFoAgBIIJoAABKIJgCABKIJACCBaAIASCCaAAASiCYAgASiCQAggWgCAEggmgAAEogmAIAEogkAIIFoAgBIIJoAABKIJgCABKIJACCBaAIASCCaAAASiCYAgASiCQAggWgCAEggmgAAEogmAIAEogkAIIFoAgBIIJoAABKIJgCABKIJACBBs6LppZdeiscee6zJtnvuuSeGDh0a/fr1iwsuuCDq6+tbdEAAgPagWdE0Y8aM+O1vf9v4/NVXX42JEyfGmDFjYtq0afHoo4/GzJkzW3xIAIB8a1Y0rVy5Mk488cTG57/85S/jiCOOiDvvvDOmTp0aN998c/znf/5niw8JAJBvzYqmTz75JMrKyhqfL1myJE455ZTG54cddlisWbOm5aYDAGgnmhVNZWVlsXr16oiI+Pzzz+OVV16Jo446qvHjdXV10bVr15adEACgHWhWNJ1yyikxbdq0WLp0aUyfPj169uwZxxxzTOPHf/vb38a+++7b4kMCAORbUXN2vv766+Nv/uZv4thjj41evXrFL37xi+jWrVvjx+fNmxdjx45t8SEBAPKtWdHUt2/fWLp0adTU1ESvXr2iS5cuTT7+wAMPRK9evVp0QACA9qBZ0bRNaWnpDrf37t37aw0DANBeNSuajj/++CgoKNhue2lpaey///5x0UUXxaBBg1psOACA9qJZ0XTwwQfvcPunn34aixYtitmzZ8ezzz77lfsBAOyqmhVNN9xww04/ftFFF8UPf/jDWLRo0dcaCgCgvWnRf7B30qRJsWLFipb8lAAA7UKLRlOPHj3is88+a8lPCQDQLrRoND355JMxbNiwlvyUAADtQrPuaXrkkUd2uL2mpiZefvnlmDt3bsyfP78l5gIAaFeaFU3f/va3d7h99913j+HDh8f8+fPjjDPOaIm5AADalWZF09atW1trDgCAdq1F72n6c9/61rdizZo1rfkSAABtolWj6d13340vvviiNV8CAKBNtGo0AQB0FHmNpmeeeSbGjx8fAwYMiIKCgli4cOFfPGbJkiVRUVER3bt3j3322Sduv/321h8UAOj08hpNGzdujJEjR8bs2bOT9l+9enWceuqpccwxx8SKFSvihz/8YUyZMiV+9atftfKkAEBn16yfnmtp48aNi3HjxiXvf/vtt8fgwYPjxhtvjIiIAw44IJYtWxb//u//Hn/7t3/bSlP+ZZ9vyeLDjQ2xbkNDrNvYEOs3NMT6jVti4+dbontRYfTrVRT9diuKfrt1ibL//XOPrt4ZBdgVZFkW1dXVUVlZGe+9917jo6qqKrZs2RJlZWUxZMiQGDJkSAwePDiGDBkS/fv3j8JCf893NHmNpuZ64YUXYuzYsU22nXzyyTF37tz44osvomvXrm0+0/2//TTmvvJpk21dCr78v1uyiMKCiIL//fM2Z3yzJCYd1rvNZgQgN3V1dbHPPvtEdXV147bCwsLo0qVLNDQ0REREUVFRbN26NbZs2dK4T48ePeKll16Kb33rW20+M62nVaPpjjvuiLKyshb7fGvXrt3u85WVlUVDQ0NUV1dHeXn5Do+rr6+P+vr6xue1tbUtNtOami+iICL+pImaBNLW7M+PiBhU2jWyLIuCgoIWmwOAlvfJJ580CaaIL39n4Z/+3sId/ZT45s2bY82aNW0eTa15vqMZ0XTzzTcnf9IpU6ZERMTZZ5/d/In+gj8PjSzLdrj9T82cOTOuu+66Fp8lImKvkq7x513UpeDLiNqafXmVqUthxJat/xdWf6z9QjAB7AL22GOP6N27d3z88ceN27p06RKFhYXR0NAQWZZFUdGXp9JtV54iIoqLi2PgwIFtPm9rnu9oRjTdcMMNTZ5/+OGHsWnTpthjjz0iIuLTTz+Nnj17Rr9+/RqjqaX1798/1q5d22Tb+vXro6ioKPbcc8+vPG769OkxderUxue1tbUxaNCgFpnpuyP3iL/9Zkms39AQ6zZuifX/e2/T+o0NUb2xIf6fHl/ey9SvV1GU7VbUeH8TAO1fSUlJfPjhh7Fu3brGe5r+9N6m+vr6GDp0aJP7mQYPHhwDBgxojKm21JrnO5oRTatXr27883333Rdz5syJuXPnxv777x8REb/73e/i+9//fkyaNKnlp/xfRx11VDz66KNNtj355JMxatSond7PVFxcHMXFxa02V/eiwhi8R7cYvEervQQAeVJYWBjl5eVRXl4eRxxxRL7H2anWPt91djnd2n/11VfHLbfc0hhMERH7779/3HDDDfGjH/0o+fNs2LAhVq5cGStXroyIL8Ns5cqVUVlZGRFfFvOECRMa9588eXK89957MXXq1HjjjTdi3rx5MXfu3Ljiiity+TIAAJLldO2wqqpqhze+bdmyJdatW5f8eZYtWxbHH3984/NtlxTPOeecmD9/flRVVTUGVETE0KFDY9GiRXHZZZfFrbfeGgMGDIibb745r79uAADoHHKKphNPPDG+//3vx9y5c6OioiIKCgpi2bJlMWnSpBgzZkzy5znuuOMab+Tekfnz52+37dhjj41XXnkll7EBAHKW09tz8+bNi7322isOP/zw6N69exQXF8cRRxwR5eXlcdddd7X0jAAAeZfTlaa+ffvGokWL4q233oo333wzsiyLAw44IIYNG9bS8wEAtAtf6+ch995778iyLPbdd9+8/GglAEBbyentuU2bNsXEiROjZ8+e8c1vfrPxZu0pU6bEv/7rv7bogAAA7UFO0TR9+vT4zW9+E08//XR07969cfuYMWNiwYIFLTYcAEB7kdN7agsXLowFCxbEkUce2eSfAxkxYkS8/fbbLTYcAEB7kdOVpg8//DD69eu33faNGzf6N9UAgA4pp2g67LDD4r//+78bn28LpTvvvDOOOuqolpkMAKAdyentuZkzZ8Ypp5wSq1atioaGhrjpppvi9ddfjxdeeCGWLFnS0jMCAORdTleaRo8eHc8//3xs2rQp9t1333jyySejrKwsXnjhhaioqGjpGQEA8q7ZV5q++OKLuOCCC+Lqq6+OX/ziF60xEwBAu9PsK01du3aNhx9+uDVmAQBot3J6e+6v//qvY+HChS08CgBA+5XTjeDf+MY34p//+Z/j+eefj4qKithtt92afHzKlCktMhwAQHuRUzTdddddsccee8Ty5ctj+fLlTT5WUFAgmgCADienaFq9enXjn7Msi4jwSy0BgA4tp3uaIiLmzp0bBx54YHTv3j26d+8eBx54YNx1110tORsAQLuR05Wmq6++Om644Ya4+OKLG38D+AsvvBCXXXZZvPvuu3H99de36JAAAPmWUzTddtttceedd8bf//3fN247/fTT46CDDoqLL75YNAEAHU5Ob89t2bIlRo0atd32ioqKaGho+NpDAQC0NzlF0z/8wz/Ebbfdtt32n//85/Hd7373aw8FANDe5PT2XMSXN4I/+eSTceSRR0ZExIsvvhhr1qyJCRMmxNSpUxv3mzVr1tefEgAgz3KKptdeey0OPfTQiIh4++23IyKib9++0bdv33jttdca9/NrCACAjiKnaPr1r3/d0nMAALRrOf+eJgCAzkQ0AQAkEE0AAAlEEwBAAtEEAJBANAEAJBBNAAAJRBMAQALRBACQQDQBACQQTQAACUQTAEAC0QQAkEA0AQAkEE0AAAlEEwBAAtEEAJBANAEAJBBNAAAJRBMAQALRBACQQDQBACQQTQAACUQTAEAC0QQAkEA0AQAkEE0AAAlEEwBAAtEEAJBANAEAJBBNAAAJRBMAQALRBACQQDQBACQQTQAACUQTAEAC0QQAkEA0AQAkEE0AAAlEEwBAAtEEAJBANAEAJBBNAAAJRBMAQIJ2EU1z5syJoUOHRvfu3aOioiKWLl260/3vvffeGDlyZPTs2TPKy8vjvPPOi48++qiNpgUAOqO8R9OCBQvi0ksvjauuuipWrFgRxxxzTIwbNy4qKyt3uP+zzz4bEyZMiIkTJ8brr78eDzzwQLz88stx/vnnt/HkAEBnkvdomjVrVkycODHOP//8OOCAA+LGG2+MQYMGxW233bbD/V988cXYe++9Y8qUKTF06ND4q7/6q5g0aVIsW7asjScHADqTvEbT559/HsuXL4+xY8c22T527Nh4/vnnd3jM6NGj4/33349FixZFlmWxbt26ePDBB+O0005ri5EBgE6qKJ8vXl1dHVu2bImysrIm28vKymLt2rU7PGb06NFx7733xllnnRWfffZZNDQ0xOmnnx633HLLV75OfX191NfXNz6vra1tmS8AANoR57vWlfe35yIiCgoKmjzPsmy7bdusWrUqpkyZEtdcc00sX748Hn/88Vi9enVMnjz5Kz//zJkzo7S0tPExaNCgFp0fANoD57vWlddo6tOnT3Tp0mW7q0rr16/f7urTNjNnzoyjjz46rrzyyjjooIPi5JNPjjlz5sS8efOiqqpqh8dMnz49ampqGh9r1qxp8a8FAPLN+a515TWaunXrFhUVFbF48eIm2xcvXhyjR4/e4TGbNm2KwsKmY3fp0iUivrxCtSPFxcVRUlLS5AEAHY3zXevK+9tzU6dOjbvuuivmzZsXb7zxRlx22WVRWVnZ+Hbb9OnTY8KECY37jx8/Ph566KG47bbb4p133onnnnsupkyZEocffngMGDAgX18GANDB5fVG8IiIs846Kz766KP48Y9/HFVVVXHggQfGokWLYsiQIRERUVVV1eR3Np177rlRV1cXs2fPjssvvzz22GOPOOGEE+InP/lJvr4EAKATKMi+6j2tDqy2tjZKS0ujpqbGpUsAOqxt57vjr5gT/fY7ON/jtBsfV/4uFv+/58Xy5cvj0EMPTT4u72/PAQDsCkQTAEAC0QQAkEA0AQAkEE0AAAlEEwBAAtEEAJBANAEAJBBNAAAJRBMAQALRBACQQDQBACQQTQAACUQTAEAC0QQAkEA0AQAkEE0AAAlEEwBAAtEEAJBANAEAJBBNAAAJRBMAQALRBACQQDQBACQQTQAACUQTAEAC0QQAkEA0AQAkEE0AAAlEEwBAAtEEAJBANAEAJBBNAAAJRBMAQALRBACQQDQBACQQTQAACUQTAEAC0QQAkEA0AQAkEE0AAAlEEwBAAtEEAJBANAEAJBBNAAAJRBMAQALRBACQQDQBACQQTQAACUQTAEAC0QQAkEA0AQAkEE0AAAlEEwBAAtEEAJBANAEAJBBNAAAJRBMAQALRBACQQDQBACQQTQAACUQTAEAC0QQAkEA0AQAkEE0AAAlEEwBAAtEEAJBANAEAJBBNAAAJ2kU0zZkzJ4YOHRrdu3ePioqKWLp06U73r6+vj6uuuiqGDBkSxcXFse+++8a8efPaaFoAoDMqyvcACxYsiEsvvTTmzJkTRx99dNxxxx0xbty4WLVqVQwePHiHx5x55pmxbt26mDt3bnzjG9+I9evXR0NDQxtPDgB0JnmPplmzZsXEiRPj/PPPj4iIG2+8MZ544om47bbbYubMmdvt//jjj8eSJUvinXfeid69e0dExN57792WIwMAnVBe3577/PPPY/ny5TF27Ngm28eOHRvPP//8Do955JFHYtSoUfHTn/409tprrxg2bFhcccUVsXnz5q98nfr6+qitrW3yAICOxvmudeU1mqqrq2PLli1RVlbWZHtZWVmsXbt2h8e888478eyzz8Zrr70WDz/8cNx4443x4IMPxkUXXfSVrzNz5swoLS1tfAwaNKhFvw4AaA+c71pXu7gRvKCgoMnzLMu227bN1q1bo6CgIO699944/PDD49RTT41Zs2bF/Pnzv/Jq0/Tp06OmpqbxsWbNmhb/GgAg35zvWlde72nq06dPdOnSZburSuvXr9/u6tM25eXlsddee0VpaWnjtgMOOCCyLIv3338/9ttvv+2OKS4ujuLi4pYdHgDaGee71pXXK03dunWLioqKWLx4cZPtixcvjtGjR+/wmKOPPjo++OCD2LBhQ+O2t956KwoLC2PgwIGtOi8A0Hnl/e25qVOnxl133RXz5s2LN954Iy677LKorKyMyZMnR8SXlxonTJjQuP/ZZ58de+65Z5x33nmxatWqeOaZZ+LKK6+M733ve9GjR498fRkAQAeX9185cNZZZ8VHH30UP/7xj6OqqioOPPDAWLRoUQwZMiQiIqqqqqKysrJx/169esXixYvj4osvjlGjRsWee+4ZZ555Zlx//fX5+hIAgE4g79EUEXHhhRfGhRdeuMOPzZ8/f7ttw4cP3+4tPQCA1pT3t+cAAHYFogkAIIFoAgBIIJoAABKIJgCABKIJACCBaAIASCCaAAASiCYAgASiCQAggWgCAEggmgAAEogmAIAEogkAIIFoAgBIIJoAABKIJgCABKIJACCBaAIASCCaAAASiCYAgASiCQAggWgCAEggmgAAEogmAIAEogkAIIFoAgBIIJoAABKIJgCABKIJACCBaAIASCCaAAASFOV7AACgddWurYyi4h75HqPdqK16N6fjRBMAdHDL/79/zfcI7U6PHj2jT58+zTpGNAFAB7dkyZLo1atXvsdoV/r06RODBw9u1jGiCQA6uIMPPjhKSkryPcYuz43gAAAJRBMAQALRBACQQDQBACQQTQAACUQTAEAC0QQAkEA0AQAkEE0AAAlEEwBAAtEEAJBANAEAJBBNAAAJRBMAQALRBACQQDQBACQoyvcA+ZBlWURE1NbW5nkSAEiz++67R0FBQb7H6NQ6ZTTV1dVFRMSgQYPyPAkApKmpqYmSkpJ8j9GpFWTbLrt0Ilu3bo0PPvigRaq9trY2Bg0aFGvWrPHN3AzWLTfWLTfWLTfWLXetsXa5nLOyLIu6ujpXqVpIp7zSVFhYGAMHDmzRz1lSUuIvlRxYt9xYt9xYt9xYt9zle+0KCgr8/64FuREcACCBaAIASCCavqbi4uK49tpro7i4ON+j7FKsW26sW26sW26sW+6sXcfUKW8EBwBoLleaAAASiCYAgASiCQAggWhKMGfOnBg6dGh07949KioqYunSpTvdf8mSJVFRURHdu3ePffbZJ26//fY2mrR9ac66PfTQQ3HSSSdF3759o6SkJI466qh44okn2nDa9qO532/bPPfcc1FUVBQHH3xw6w7YTjV33err6+Oqq66KIUOGRHFxcey7774xb968Npq2/Wjuut17770xcuTI6NmzZ5SXl8d5550XH330URtN2z4888wzMX78+BgwYEAUFBTEwoUL/+IxzgsdRMZO/fKXv8y6du2a3XnnndmqVauySy65JNttt92y9957b4f7v/POO1nPnj2zSy65JFu1alV25513Zl27ds0efPDBNp48v5q7bpdcckn2k5/8JPuf//mf7K233sqmT5+ede3aNXvllVfaePL8au66bfPpp59m++yzTzZ27Nhs5MiRbTNsO5LLup1++unZEUcckS1evDhbvXp19tJLL2XPPfdcG06df81dt6VLl2aFhYXZTTfdlL3zzjvZ0qVLs29+85vZt7/97TaePL8WLVqUXXXVVdmvfvWrLCKyhx9+eKf7Oy90HKLpLzj88MOzyZMnN9k2fPjwbNq0aTvc/5/+6Z+y4cOHN9k2adKk7Mgjj2y1Gduj5q7bjowYMSK77rrrWnq0di3XdTvrrLOyH/3oR9m1117bKaOpuev22GOPZaWlpdlHH33UFuO1W81dt3/7t3/L9tlnnybbbr755mzgwIGtNmN7lxJNzgsdh7fnduLzzz+P5cuXx9ixY5tsHzt2bDz//PM7POaFF17Ybv+TTz45li1bFl988UWrzdqe5LJuf27r1q1RV1cXvXv3bo0R26Vc1+3uu++Ot99+O6699trWHrFdymXdHnnkkRg1alT89Kc/jb322iuGDRsWV1xxRWzevLktRm4Xclm30aNHx/vvvx+LFi2KLMti3bp18eCDD8Zpp53WFiPvspwXOo5O+W/Ppaquro4tW7ZEWVlZk+1lZWWxdu3aHR6zdu3aHe7f0NAQ1dXVUV5e3mrzthe5rNuf+9nPfhYbN26MM888szVGbJdyWbff//73MW3atFi6dGkUFXXO/znnsm7vvPNOPPvss9G9e/d4+OGHo7q6Oi688ML4+OOPO819Tbms2+jRo+Pee++Ns846Kz777LNoaGiI008/PW655Za2GHmX5bzQcbjSlODP/2XoLMt2+q9F72j/HW3v6Jq7btvcf//9MWPGjFiwYEH069evtcZrt1LXbcuWLXH22WfHddddF8OGDWur8dqt5ny/bd26NQoKCuLee++Nww8/PE499dSYNWtWzJ8/v1NdbYpo3rqtWrUqpkyZEtdcc00sX748Hn/88Vi9enVMnjy5LUbdpTkvdAyd8z9NE/Xp0ye6dOmy3X91rV+/frv/atimf//+O9y/qKgo9txzz1abtT3JZd22WbBgQUycODEeeOCBGDNmTGuO2e40d93q6upi2bJlsWLFivjBD34QEV/GQJZlUVRUFE8++WSccMIJbTJ7PuXy/VZeXh577bVXlJaWNm474IADIsuyeP/992O//fZr1Znbg1zWbebMmXH00UfHlVdeGRERBx10UOy2225xzDHHxPXXX++KyVdwXug4XGnaiW7dukVFRUUsXry4yfbFixfH6NGjd3jMUUcdtd3+Tz75ZIwaNSq6du3aarO2J7msW8SXV5jOPffcuO+++zrlPRLNXbeSkpJ49dVXY+XKlY2PyZMnx/777x8rV66MI444oq1Gz6tcvt+OPvro+OCDD2LDhg2N2956660oLCyMgQMHtuq87UUu67Zp06YoLGx62ujSpUtE/N+VE7bnvNCB5OkG9F3Gth/JnTt3brZq1ars0ksvzXbbbbfs3XffzbIsy6ZNm5b94z/+Y+P+23609LLLLstWrVqVzZ07t1P+aGlz1+2+++7LioqKsltvvTWrqqpqfHz66af5+hLyornr9uc660/PNXfd6urqsoEDB2bf+c53stdffz1bsmRJtt9++2Xnn39+vr6EvGjuut19991ZUVFRNmfOnOztt9/Onn322WzUqFHZ4Ycfnq8vIS/q6uqyFStWZCtWrMgiIps1a1a2YsWKxl/V4LzQcYmmBLfeems2ZMiQrFu3btmhhx6aLVmypPFj55xzTnbsscc22f/pp5/ODjnkkKxbt27Z3nvvnd12221tPHH70Jx1O/bYY7OI2O5xzjnntP3gedbc77c/1VmjKcuav25vvPFGNmbMmKxHjx7ZwIEDs6lTp2abNm1q46nzr7nrdvPNN2cjRozIevTokZWXl2ff/e53s/fff7+Np86vX//61zv9+8p5oeMqyDLXVAEA/hL3NAEAJBBNAAAJRBMAQALRBACQQDQBACQQTQAACUQTAEAC0QQAkEA0AQAkEE1AsuOOOy4uvfTS7bYvXLgwCgoKIiJiy5YtMXPmzBg+fHj06NEjevfuHUceeWTcfffdbTwtQMsqyvcAQMcyY8aM+PnPfx6zZ8+OUaNGRW1tbSxbtiw++eSTfI8G8LWIJqBFPfroo3HhhRfGGWec0bht5MiReZwIoGV4ew5oUf3794+nnnoqPvzww3yPAtCiRBPQombNmhUffvhh9O/fPw466KCYPHlyPPbYY/keC+BrE01AixoxYkS89tpr8eKLL8Z5550X69ati/Hjx8f555+f79EAvhbRBCQrKSmJmpqa7bZ/+umnUVJS0vi8sLAwDjvssLjsssvi4Ycfjvnz58fcuXNj9erVbTkuQIsSTUCy4cOHx7Jly7bb/vLLL8f+++//lceNGDEiIiI2btzYarMBtLaCLMuyfA8B7BrefffdGDFiRJx33nlxwQUXRI8ePWLx4sVx+eWXx3/8x3/EGWecEd/5znfi6KOPjtGjR0f//v1j9erVMX369Pj444/j9ddfj6IiP7QL7JpEE9Asy5cvj6uuuipWrFgRn332WQwbNiwuv/zy+Lu/+7uIiLjzzjvj/vvvj9deey1qamqif//+ccIJJ8SMGTNiyJAheZ4eIHeiCQAggXuaAAASiCYAgASiCQAggWgCAEggmgAAEogmAIAEogkAIIFoAgBIIJoAABKIJgCABKIJACCBaAIASPD/A1petuwG4GLDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 600x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(x=\"US\", y=\"pred_US\", data=t, kind=\"hex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T23:54:37.077170Z",
     "start_time": "2024-02-21T23:54:36.987466Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_US</th>\n",
       "      <th>pred_ctrl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7496.0</td>\n",
       "      <td>7496.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pred_US  pred_ctrl\n",
       "count   7496.0     7496.0\n",
       "mean       1.0        1.0\n",
       "std        0.0        0.0\n",
       "min        1.0        1.0\n",
       "25%        1.0        1.0\n",
       "50%        1.0        1.0\n",
       "75%        1.0        1.0\n",
       "max        1.0        1.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T23:41:40.126224Z",
     "start_time": "2024-02-21T23:41:31.601134Z"
    }
   },
   "outputs": [],
   "source": [
    " pred = main_model.predict(X_test, batch_size=main_params['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T23:44:20.971527Z",
     "start_time": "2024-02-21T23:44:20.885469Z"
    }
   },
   "outputs": [],
   "source": [
    "# write actual and predicted to \n",
    "t = pd.merge(pd.DataFrame(Y_test).T, preds, left_index=True, right_index=True)\n",
    "t.to_csv(f\"{model_name}.preds.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T23:40:18.912555Z",
     "start_time": "2024-02-21T23:37:13.172623Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = pd.merge(pd.DataFrame(test_us_pred), pd.DataFrame(test_ctrl_pred), left_index=True, right_index=True)\n",
    "preds.columns = [\"pred_US\", \"pred_ctrl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T23:40:18.912555Z",
     "start_time": "2024-02-21T23:37:13.172623Z"
    }
   },
   "outputs": [],
   "source": [
    "# run for each set and enhancer type\n",
    "train_us_pred = summary_statistics(X_train, Y_train, \"train\", \"US\")\n",
    "train_ctrl_pred = summary_statistics(X_train, Y_train, \"train\", \"ctrl\")\n",
    "val_us_pred = summary_statistics(X_valid, Y_valid, \"validation\", \"US\")\n",
    "val_ctrl_pred = summary_statistics(X_valid, Y_valid, \"validation\", \"ctrl\")\n",
    "\n",
    "test_us_pred = summary_statistics(X_test, Y_test, \"test\", \"US\")\n",
    "test_ctrl_pred = summary_statistics(X_test, Y_test, \"test\", \"ctrl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T23:37:12.325361Z",
     "start_time": "2024-02-21T23:37:12.322565Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T23:53:34.181455Z",
     "start_time": "2024-02-21T23:53:34.175904Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T23:48:50.581832Z",
     "start_time": "2024-02-21T23:48:50.579125Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model performance: mean squared error (MSE) and Pearson (PCC) and Spearman (SCC) correlation coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T20:30:23.817097Z",
     "start_time": "2024-02-21T20:01:22.983617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 75019 samples, validate on 3518 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-21 12:01:25.713407: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2024-02-21 12:01:25.776924: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2494220000 Hz\n",
      "2024-02-21 12:01:25.781128: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2080020 executing computations on platform Host. Devices:\n",
      "2024-02-21 12:01:25.781378: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2024-02-21 12:01:25.788566: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-02-21 12:01:25.788584: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-02-21 12:01:25.788635: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (dev2): /proc/driver/nvidia/version does not exist\n",
      "2024-02-21 12:01:26.951284: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75019/75019 [==============================] - 317s 4ms/step - loss: 8.3868 - Dense_US_loss: 5.1583 - Dense_ctrl_loss: 3.2285 - Dense_US_acc: 0.6764 - Dense_ctrl_acc: 0.7975 - val_loss: 7.8806 - val_Dense_US_loss: 4.7990 - val_Dense_ctrl_loss: 3.0815 - val_Dense_US_acc: 0.6990 - val_Dense_ctrl_acc: 0.8067\n",
      "Epoch 2/10\n",
      "75019/75019 [==============================] - 293s 4ms/step - loss: 8.3868 - Dense_US_loss: 5.1583 - Dense_ctrl_loss: 3.2285 - Dense_US_acc: 0.6764 - Dense_ctrl_acc: 0.7975 - val_loss: 7.8806 - val_Dense_US_loss: 4.7990 - val_Dense_ctrl_loss: 3.0815 - val_Dense_US_acc: 0.6990 - val_Dense_ctrl_acc: 0.8067\n",
      "Epoch 3/10\n",
      "75019/75019 [==============================] - 286s 4ms/step - loss: 8.3868 - Dense_US_loss: 5.1583 - Dense_ctrl_loss: 3.2285 - Dense_US_acc: 0.6764 - Dense_ctrl_acc: 0.7975 - val_loss: 7.8806 - val_Dense_US_loss: 4.7990 - val_Dense_ctrl_loss: 3.0815 - val_Dense_US_acc: 0.6990 - val_Dense_ctrl_acc: 0.8067\n",
      "Epoch 4/10\n",
      "75019/75019 [==============================] - 285s 4ms/step - loss: 8.3868 - Dense_US_loss: 5.1583 - Dense_ctrl_loss: 3.2285 - Dense_US_acc: 0.6764 - Dense_ctrl_acc: 0.7975 - val_loss: 7.8806 - val_Dense_US_loss: 4.7990 - val_Dense_ctrl_loss: 3.0815 - val_Dense_US_acc: 0.6990 - val_Dense_ctrl_acc: 0.8067\n",
      "Epoch 5/10\n",
      "75019/75019 [==============================] - 279s 4ms/step - loss: 8.3868 - Dense_US_loss: 5.1583 - Dense_ctrl_loss: 3.2285 - Dense_US_acc: 0.6764 - Dense_ctrl_acc: 0.7975 - val_loss: 7.8806 - val_Dense_US_loss: 4.7990 - val_Dense_ctrl_loss: 3.0815 - val_Dense_US_acc: 0.6990 - val_Dense_ctrl_acc: 0.8067\n",
      "Epoch 6/10\n",
      "75019/75019 [==============================] - 277s 4ms/step - loss: 8.3868 - Dense_US_loss: 5.1583 - Dense_ctrl_loss: 3.2285 - Dense_US_acc: 0.6764 - Dense_ctrl_acc: 0.7975 - val_loss: 7.8806 - val_Dense_US_loss: 4.7990 - val_Dense_ctrl_loss: 3.0815 - val_Dense_US_acc: 0.6990 - val_Dense_ctrl_acc: 0.8067\n"
     ]
    }
   ],
   "source": [
    "main_model, main_params = DeepSTARR()\n",
    "main_model, my_history = train(main_model, X_train, Y_train, X_valid, Y_valid, main_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T20:01:22.183309Z",
     "start_time": "2024-02-21T20:01:22.179448Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(selected_model, X_train, Y_train, X_valid, Y_valid, params):\n",
    "\n",
    "    my_history=selected_model.fit(X_train, Y_train,\n",
    "                                  validation_data=(X_valid, Y_valid),\n",
    "                                  batch_size=params['batch_size'], epochs=params['epochs'],\n",
    "                                  callbacks=[EarlyStopping(patience=params['early_stop'], monitor=\"val_loss\", restore_best_weights=True),\n",
    "                                             History()])\n",
    "    \n",
    "    return selected_model, my_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training DeepSTARR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T20:00:55.575589Z",
     "start_time": "2024-02-21T20:00:54.002647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /wynton/home/ahituv/fongsl/micromamba/envs/DeepSTARR/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /wynton/home/ahituv/fongsl/micromamba/envs/DeepSTARR/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /wynton/home/ahituv/fongsl/micromamba/envs/DeepSTARR/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /wynton/home/ahituv/fongsl/micromamba/envs/DeepSTARR/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /wynton/home/ahituv/fongsl/micromamba/envs/DeepSTARR/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /wynton/home/ahituv/fongsl/micromamba/envs/DeepSTARR/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /wynton/home/ahituv/fongsl/micromamba/envs/DeepSTARR/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /wynton/home/ahituv/fongsl/micromamba/envs/DeepSTARR/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /wynton/home/ahituv/fongsl/micromamba/envs/DeepSTARR/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 271, 4)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1D_1st (Conv1D)             (None, 271, 256)     7424        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 271, 256)     1024        Conv1D_1st[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 271, 256)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 135, 256)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv1D_2 (Conv1D)               (None, 135, 60)      46140       max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 135, 60)      240         Conv1D_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 135, 60)      0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 67, 60)       0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv1D_3 (Conv1D)               (None, 67, 60)       18060       max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 67, 60)       240         Conv1D_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 67, 60)       0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 33, 60)       0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv1D_4 (Conv1D)               (None, 33, 120)      21720       max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 33, 120)      480         Conv1D_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 33, 120)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 16, 120)      0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1920)         0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Dense_1 (Dense)                 (None, 256)          491776      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 256)          1024        Dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 256)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Dense_2 (Dense)                 (None, 256)          65792       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 256)          1024        Dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 256)          0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Dense_US (Dense)                (None, 1)            257         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Dense_ctrl (Dense)              (None, 1)            257         dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 655,458\n",
      "Trainable params: 653,442\n",
      "Non-trainable params: 2,016\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'batch_size': 128,\n",
       " 'epochs': 10,\n",
       " 'early_stop': 10,\n",
       " 'kernel_size1': 7,\n",
       " 'kernel_size2': 3,\n",
       " 'kernel_size3': 5,\n",
       " 'kernel_size4': 3,\n",
       " 'lr': 0.002,\n",
       " 'num_filters': 256,\n",
       " 'num_filters2': 60,\n",
       " 'num_filters3': 60,\n",
       " 'num_filters4': 120,\n",
       " 'n_conv_layer': 4,\n",
       " 'n_add_layer': 2,\n",
       " 'dropout_prob': 0.4,\n",
       " 'dense_neurons1': 256,\n",
       " 'dense_neurons2': 256,\n",
       " 'pad': 'same',\n",
       " 'n_nucleotides': 4,\n",
       " 'seq_len': 271,\n",
       " 'pred_task': 'class',\n",
       " 'prefix': 'class.all',\n",
       " 'data_path': '/wynton/home/ahituv/fongsl/EMF/US/ml_emf/data/deepstarr'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DeepSTARR()[0].summary()\n",
    "DeepSTARR()[1] # dictionary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepSTARR",
   "language": "python",
   "name": "deepstarr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
