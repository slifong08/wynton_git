{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "712c186e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T01:26:13.718450Z",
     "start_time": "2023-05-31T01:26:11.201066Z"
    }
   },
   "outputs": [],
   "source": [
    "from Bio.Align import PairwiseAligner\n",
    "from Bio.SeqIO.FastaIO import SimpleFastaParser\n",
    "from Bio.SeqUtils import gc_fraction\n",
    "import config_readwrite as crw\n",
    "from collections import Counter\n",
    "import gzip\n",
    "from itertools import product, combinations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plot_params as pp\n",
    "pp.fonts()\n",
    "\n",
    "import subprocess as sp\n",
    "\n",
    "NMER, MIN_HOMOPOLYMER_LEN = 15, 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb12c195",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5d6756",
   "metadata": {},
   "source": [
    "    PAM = \"NGG\"\n",
    "    A|G in pos 19 or 20 (position 11,12 of nullomer)\n",
    "    no homoploymer\n",
    "    gc content between 40-60%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e1d236b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T00:44:39.938462Z",
     "start_time": "2023-05-31T00:44:39.925747Z"
    }
   },
   "outputs": [],
   "source": [
    "config_tag = \"config\"\n",
    "config, cfn = crw.read_config(os.path.join(os.getcwd(), config_tag))\n",
    "\n",
    "NULLS_TSV = config[\"nullomers\"][f\"{NMER}mer_fo\"]\n",
    "NULLS_FA = config[\"nullomers\"][f\"{NMER}mer_fo_fa\"]\n",
    "\n",
    "SEED_FA = config[\"seed\"][f\"{NMER}mer_fa\"]\n",
    "SEED_TSV = config[\"seed\"][f\"{NMER}mer_tsv\"]\n",
    "\n",
    "SEED_1bp = config[\"seed\"][f\"{NMER}mer_1bprelated\"]\n",
    "SEED_morethan1bp = config[\"seed\"][f\"{NMER}mer_morethan1bprelated\"]\n",
    "\n",
    "SEED_1bp_fa = config[\"seed\"][f\"{NMER}mer_1bprelated_fa\"]\n",
    "SEED_morethan1bp_fa = config[\"seed\"][f\"{NMER}mer_morethan1bprelated_fa\"]\n",
    "\n",
    "RE= config[f\"seed\"][\"results\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d15ef52",
   "metadata": {},
   "source": [
    "# convert to fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b07b73df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T00:42:16.043883Z",
     "start_time": "2023-05-31T00:42:15.920007Z"
    }
   },
   "outputs": [],
   "source": [
    "if os.path.exists(NULLS_FA) is False:\n",
    "    writer = open(NULLS_FA, \"w\")\n",
    "    with open(NULLS_TSV, \"r\") as reader:\n",
    "        for n, line in enumerate(reader.readlines()):\n",
    "            writer.write(f\">{NMER}-firstorder.{n}\\n{line}\")\n",
    "    writer.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dbe53f",
   "metadata": {},
   "source": [
    "# read the fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d646ed8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T00:42:20.559096Z",
     "start_time": "2023-05-31T00:42:16.047114Z"
    }
   },
   "outputs": [],
   "source": [
    "seqs = {}\n",
    "with open(NULLS_FA, \"r\") as reader:\n",
    "    for value in SimpleFastaParser(reader):\n",
    "        seq_id, seq = value\n",
    "        seqs[seq_id] = seq.split(\"\\t\")[0]\n",
    "reader.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56c84616",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T00:42:21.114431Z",
     "start_time": "2023-05-31T00:42:20.561373Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('15-firstorder.0', 'AAAACGCGTCGGCGA'),\n",
       " ('15-firstorder.1', 'AAAATCGTCGGACGT'),\n",
       " ('15-firstorder.2', 'AAAATCGCGCTTCGA')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(seqs.items())[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c7fc29",
   "metadata": {},
   "source": [
    "# find the pam sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29962b89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T00:42:21.263645Z",
     "start_time": "2023-05-31T00:42:21.116107Z"
    }
   },
   "outputs": [],
   "source": [
    "def assessPAM(seq):\n",
    "    if \"\".join(seq[-2:]) == \"GG\":\n",
    "        pam = True\n",
    "    else:\n",
    "        pam = False\n",
    "        \n",
    "    return pam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b69d2953",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T00:42:21.633672Z",
     "start_time": "2023-05-31T00:42:21.266602Z"
    }
   },
   "outputs": [],
   "source": [
    "def assessPur(seq):\n",
    "    \n",
    "    PURS = [\"A\", \"G\"]\n",
    "\n",
    "    if seq[-4] in PURS or seq[-5] in PURS: # assume NGG in seq[-3:]\n",
    "        PUR=True\n",
    "    \n",
    "    else:\n",
    "        PUR=False\n",
    "    \n",
    "    return PUR    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c900a20b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T00:42:21.730556Z",
     "start_time": "2023-05-31T00:42:21.636242Z"
    }
   },
   "outputs": [],
   "source": [
    "def makeHomopolymer(seq_len, min_homopolymer_len):\n",
    "    \n",
    "    BASES = [\"A\", \"C\", \"G\", \"T\"]\n",
    "    homopolymer_list = []\n",
    "    for base in BASES:\n",
    "        \n",
    "        # make homopolymers between min length and full seq len\n",
    "        for i in np.arange(min_homopolymer_len, seq_len+1):  \n",
    "            homopolymer_list.append((base*i))\n",
    "\n",
    "    return homopolymer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c3023f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T00:42:21.819308Z",
     "start_time": "2023-05-31T00:42:21.733648Z"
    }
   },
   "outputs": [],
   "source": [
    "def assessNoHomopolymers(seq, homoploymer_list):\n",
    "    \n",
    "    # assume no homopolymer in seq\n",
    "    no_homopolymer = True\n",
    "    \n",
    "    # unless one of the homopolymers is in the sequence\n",
    "    for homoploymer in homoploymer_list:\n",
    "        if homoploymer in seq:\n",
    "            no_homopolymer = False\n",
    "    \n",
    "    return no_homopolymer        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3171684a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T00:42:21.942683Z",
     "start_time": "2023-05-31T00:42:21.823063Z"
    }
   },
   "outputs": [],
   "source": [
    "def assessGcContent(seq):\n",
    "    good_gc = False\n",
    "    \n",
    "    # get gc fraction\n",
    "    gc = gc_fraction(seq)\n",
    "    \n",
    "    # if gc content between 40-60\n",
    "    if gc >=0.40 and gc<=0.60:\n",
    "        good_gc = True\n",
    "    \n",
    "    return good_gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25dbaced",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T00:42:22.320427Z",
     "start_time": "2023-05-31T00:42:21.944670Z"
    }
   },
   "outputs": [],
   "source": [
    "def writeDictToFa(result_dict, outfile):\n",
    "    with open(outfile, \"w\") as writer:\n",
    "        for key, value in result_dict.items():\n",
    "            writer.write(f\">{key}\\n{value}\\n\")\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd1ffd3",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfffdd1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T00:45:36.130627Z",
     "start_time": "2023-05-31T00:45:33.186829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('15-firstorder.701', 'AAACCGATCGTGCGG'), ('15-firstorder.743', 'AAACCGCGCTTACGG'), ('15-firstorder.790', 'AAACGATTCGAGCGG')] npam 128910 n pur 110649 n no homopolymer 107449 n gc<=60, >=40 60682\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "filter nullomers\n",
    "\n",
    "input \n",
    "    seq length (int) - length of the sequence\n",
    "    min_homopolymer_len (int) - the minimum homopolymer length to be excluded\n",
    "\n",
    "method\n",
    "    1. make list of homopolymers to look out for, based on min_homopolymer_len\n",
    "    2. parse through first order seqeunces\n",
    "        2.1 count the number of sequences that \n",
    "            meet the pam, purine, nohomopolymer or gc content rules\n",
    "    3. Pam? \n",
    "    4. purine in pos 19 or 20?\n",
    "    5. no homopolymers? \n",
    "    6. meets gc requirements (gc content >=40%, <= 60%)\n",
    "    7. if all requirements met, add to list\n",
    "    8. report the number of sequences that pass each requirement. \n",
    "    9. make a dataframe of the sequences that meet requirements. \n",
    "    10. sort sequences, rename columns, write sequences that meet requirements to file\n",
    "    11. make dictionary and write fa file of sequences that meet requirements. \n",
    "\"\"\"\n",
    "if os.path.exists(SEED_TSV) is False:\n",
    "    #1 make once - homopolymer list to reference against\n",
    "    homopolymer_list = makeHomopolymer(len(seq), MIN_HOMOPOLYMER_LEN)\n",
    "\n",
    "    #2 parse through candidate sequences\n",
    "    candidates = {}\n",
    "    \n",
    "    #2.1\n",
    "    pam, pur, nohomo, gc_ = 0, 0, 0, 0\n",
    "    \n",
    "    for seq_id, seq in seqs.items():\n",
    "        \n",
    "        #3\n",
    "        if assessPAM(seq) is True:  # seq contains PAM? \n",
    "            pam += 1\n",
    "            \n",
    "            #4\n",
    "            if assessPur(seq) is True:\n",
    "                pur += 1\n",
    "                \n",
    "                #5\n",
    "                if assessNoHomopolymers(seq, homopolymer_list) is True:\n",
    "                    nohomo += 1\n",
    "                    \n",
    "                    #6\n",
    "                    if assessGcContent(seq) is True:\n",
    "                        gc_ += 1\n",
    "                        \n",
    "                        #7\n",
    "                        candidates[seq_id] = seq\n",
    "    #8\n",
    "    print(list(candidates.items())[:3], \"npam\",\n",
    "          pam, \"n pur\", pur, \n",
    "          \"n no homopolymer\", nohomo, \n",
    "          \"n gc<=60, >=40\", gc_)\n",
    "\n",
    "    #9 make into a dataframe to sort based on str similarity\n",
    "    df = pd.DataFrame(candidates.items())\n",
    "\n",
    "    #10 sort sequences\n",
    "    df = df.sort_values(by=1).reset_index()\n",
    "    df.columns = [\"idx\", \"id\", \"seq\"]\n",
    "    df[[\"id\", \"seq\"]].to_csv(SEED_TSV, sep='\\t', index=None)\n",
    "    \n",
    "    #11 make dictionary of sorted sequences\n",
    "    sorted_candidates = dict(zip(df[\"id\"], df[\"seq\"]))\n",
    "\n",
    "    # write dictionary to fa\n",
    "    writeDictToFa(sorted_candidates, SEED_FA)\n",
    "else:\n",
    "    df = pd.read_csv(SEED_TSV, sep='\\t')\n",
    "\n",
    "df = df[[\"id\", \"seq\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5d659f",
   "metadata": {},
   "source": [
    "# Pairwise alignment to remove identical sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "88f908a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T01:22:27.251937Z",
     "start_time": "2023-05-31T01:22:27.246819Z"
    }
   },
   "outputs": [],
   "source": [
    "def PairwiseAlign(seq1, seq2):\n",
    "\n",
    "    aligner = PairwiseAligner()\n",
    "    \n",
    "    alignment = aligner.align(seq1[:-3], seq2[:-3])  #[:-3] ignores the pam site\n",
    "    \n",
    "    return alignment.score  # return number of bases that match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e65c58a",
   "metadata": {},
   "source": [
    "# find alignments 1 bp away\n",
    "- randomly pick one alignment to keep, one to toss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1325161",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T22:35:29.688172Z",
     "start_time": "2023-05-30T22:07:40.569809Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "find onebpaway_matchsize for nullomer of length NMER\n",
    "    - 3 bases, to ignore for pam site  \n",
    "    - 1 base, reflects 1bp difference between matching sequence \n",
    "\"\"\"\n",
    "onebpaway_matchsize = NMER - (3 + 1)\n",
    "\n",
    "\"\"\"\n",
    "pairwise align the sequences, looking for matches.\n",
    "\n",
    "input \n",
    "    candidates.values() (dictionary of nullomer values) - \n",
    "            nullomers filtered for first order, PAM, PUR \n",
    "            in pos 19|20, GC content, no homopolymers\n",
    "            \n",
    "    SEED_1bp_fa (str) - file to write all the nullomers 1bp \n",
    "            away in distance, ignoring pam. \n",
    "    \n",
    "method\n",
    "    1. if SEED_1bp_fa does not exist, \n",
    "        perform pairwise alignments to find sequences that \n",
    "        match by 1 bp. \n",
    "    2. make 2 lists from the same nullomer values.\n",
    "        2.1 shuffle 1 list for randomness. \n",
    "    3. make one_bp (list), a list to collect all sequences related by 1bp\n",
    "    4. per sequence in nullomer list 1\n",
    "        4.1 check that you haven't evaluated this first sequence (s1)\n",
    "            and all its pairs already.\n",
    "        4.2 test pairwise alignment in all sequences in list 2\n",
    "        4.3 check that you haven't evaluated this second sequence (s2)\n",
    "            and all its pairs already, or that it isn't identical with s1\n",
    "    5. pairwise align, score how many bases match for two aligned sequences, ignoring pam site\n",
    "    6. count the number of times that score appears\n",
    "    7. test if alignment score matches all bases but one base\n",
    "        7.1 if one bp difference, then randomly choose one sequence to remove from pool\n",
    "\n",
    "return\n",
    "    one_bp (list) - list of all sequences that are related by one basepair to remove. \n",
    "                    Note, this is not all the 1bp away sequences because some\n",
    "                    are randomly chosen to remain in the pool\n",
    "    counter (dictionary) - counter of how many times pairs of sequences had a matching score. \n",
    "        \n",
    "\n",
    "\"\"\"\n",
    "#1 this take 13 minutes to run\n",
    "if os.path.exists(SEED_1bp_fa) is False:\n",
    "\n",
    "    #2 \n",
    "    l1, l2 = list(candidates.values()), list(candidates.values())\n",
    "\n",
    "    #2.1 shuffle, for diversity sake\n",
    "    np.random.shuffle(l1)\n",
    "    \n",
    "    #3\n",
    "    one_bp, counter = set(), Counter()\n",
    "    \n",
    "    #4\n",
    "    for s1 in l1:\n",
    "\n",
    "        # 4.1\n",
    "        if s1 not in one_bp:\n",
    "            \n",
    "            #4.2\n",
    "            for s2 in l2:\n",
    "\n",
    "                #4.3\n",
    "                if s2 not in one_bp and s2 != s1:\n",
    "\n",
    "                    #5 \n",
    "                    score = PairwiseAlign(s1, s2)\n",
    "\n",
    "                    #6 count score distribution\n",
    "                    counter[score] += 1\n",
    "\n",
    "                    #7 if the alignment score equals the onebpaway matchsize\n",
    "                    if score >= onebpaway_matchsize:\n",
    "\n",
    "                        #7.1 randomly add one of the sequences to be removed.\n",
    "                        # Keep the other in the pool.\n",
    "                        one_bp.add(list(np.random.choice([s1, s2], size=1))[0])\n",
    "\n",
    "                        # print(\"found a match\", s1, s2)\n",
    "\n",
    "    len(one_bp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6655259",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T22:36:00.715820Z",
     "start_time": "2023-05-30T22:36:00.707368Z"
    }
   },
   "outputs": [],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e65e2d1",
   "metadata": {},
   "source": [
    "# save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01bcd051",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T01:05:36.860915Z",
     "start_time": "2023-05-31T01:05:36.853245Z"
    }
   },
   "outputs": [],
   "source": [
    "def writeTsvFa(df, out_tsv, out_fa):\n",
    "    print(df.shape)\n",
    "    # rename columns\n",
    "    if \"seq\" not in df.columns:\n",
    "        df.columns=[\"idx\", \"id\", \"seq\"]\n",
    "    \n",
    "    # sort by seq\n",
    "    df=df.sort_values(by=\"seq\")\n",
    "    \n",
    "    #save id, seq to tsv\n",
    "    df[[\"id\", \"seq\"]].to_csv(out_tsv, sep='\\t', index=False)\n",
    "\n",
    "    # make dictionary of candidates\n",
    "    sorted_candidates = dict(zip(df[\"id\"], df['seq']))\n",
    "\n",
    "    # write dictionary to fa\n",
    "    writeDictToFa(sorted_candidates, out_fa)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bfd401",
   "metadata": {},
   "source": [
    "## write sequences related by 1 bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "797527d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T01:06:33.125381Z",
     "start_time": "2023-05-31T01:06:32.857021Z"
    }
   },
   "outputs": [],
   "source": [
    "if os.path.exists(SEED_1bp) is False:\n",
    "    related = df.loc[df[1].isin(list(one_bp))]\n",
    "    out_tsv, out_fa = SEED_1bp, SEED_1bp_fa\n",
    "    writeTsvFa(related, out_tsv, out_fa)\n",
    "    \n",
    "else:\n",
    "    related = pd.read_csv(SEED_1bp, sep='\\t',)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f2f501",
   "metadata": {},
   "source": [
    "## write sequence related by more than 1 bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "320df1f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T01:08:41.470736Z",
     "start_time": "2023-05-31T01:08:41.439928Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15-firstorder.2100</td>\n",
       "      <td>AAACAACGATCGCGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15-firstorder.1087</td>\n",
       "      <td>AAACATCGTACGCGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15-firstorder.3439</td>\n",
       "      <td>AAACCCGACGTACGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15-firstorder.3182</td>\n",
       "      <td>AAACCGCGCGATAGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15-firstorder.981</td>\n",
       "      <td>AAACCGTCGATGCGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4218</th>\n",
       "      <td>15-firstorder.2479500</td>\n",
       "      <td>TTTGACGAATCGCGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4219</th>\n",
       "      <td>15-firstorder.2479390</td>\n",
       "      <td>TTTGCGGTCGTACGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4220</th>\n",
       "      <td>15-firstorder.2479145</td>\n",
       "      <td>TTTGGCGATCGACGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4221</th>\n",
       "      <td>15-firstorder.2479018</td>\n",
       "      <td>TTTGGCGCGAATCGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4222</th>\n",
       "      <td>15-firstorder.2478961</td>\n",
       "      <td>TTTGTCGTGTCGCGG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4223 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id              seq\n",
       "0        15-firstorder.2100  AAACAACGATCGCGG\n",
       "1        15-firstorder.1087  AAACATCGTACGCGG\n",
       "2        15-firstorder.3439  AAACCCGACGTACGG\n",
       "3        15-firstorder.3182  AAACCGCGCGATAGG\n",
       "4         15-firstorder.981  AAACCGTCGATGCGG\n",
       "...                     ...              ...\n",
       "4218  15-firstorder.2479500  TTTGACGAATCGCGG\n",
       "4219  15-firstorder.2479390  TTTGCGGTCGTACGG\n",
       "4220  15-firstorder.2479145  TTTGGCGATCGACGG\n",
       "4221  15-firstorder.2479018  TTTGGCGCGAATCGG\n",
       "4222  15-firstorder.2478961  TTTGTCGTGTCGCGG\n",
       "\n",
       "[4223 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.exists(SEED_morethan1bp) is False:\n",
    "    less_related=df.loc[~df[1].isin(list(one_bp))]\n",
    "\n",
    "    out_tsv, out_fa = SEED_morethan1bp, SEED_morethan1bp_fa\n",
    "    \n",
    "    # write tsv, fa\n",
    "    writeTsvFa(less_related, out_tsv, out_fa)\n",
    "    \n",
    "else:\n",
    "    less_related= pd.read_csv(SEED_morethan1bp, sep='\\t')\n",
    "\n",
    "#view\n",
    "less_related"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/slifong08/0f4c833c116f9c6b47d5fb9f6c7a95c9"
  },
  "gist": {
   "data": {
    "description": "nullomers/bin-lock/1_design_nullomers/1_design_Nmers.ipynb",
    "public": false
   },
   "id": "0f4c833c116f9c6b47d5fb9f6c7a95c9"
  },
  "kernelspec": {
   "display_name": "Python (wynenv)",
   "language": "python",
   "name": "wynenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
