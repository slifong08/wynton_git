{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92d4061",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T21:57:32.916931Z",
     "start_time": "2023-04-28T21:57:23.602369Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import h5py\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.append(\"/wynton/home/ahituv/fongsl/tools/py_\")\n",
    "\n",
    "import config_readwrite as crw\n",
    "\n",
    "import plot_params as pp\n",
    "pp.fonts()\n",
    "\n",
    "\n",
    "# parse args\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"file\", type=str, help=\"full path to hdf5 file\")\n",
    "parser.add_argument(\"cellline\", type=str, help = \"cellline\")\n",
    "parser.add_argument(\"kmer_length\", type=int, help = \"length of kmer\")\n",
    "parser.add_argument(\"n_mut\", type=int, help = \"number of mutations to make\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "FILE, CL, KMER_LEN, NMUTS = args.file, args.cellline, args.kmer_length, args.n_mut\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "CL, MER, NMUTS = \"common\", 15, 2\n",
    "COOR=\"chr10:133080140-133080340\"\n",
    "PATH = \"/wynton/home/ahituv/fongsl/nullomers/data/lock/common/concatmers/sei_predictions/chromatin-profiles-hdf5\"\n",
    "FILE = os.path.join(\n",
    "    PATH, f\"common.{MER}mers.{NMUTS}mut.nulls.fo.pam.CONCAT-10.ext4096.{COOR}_predictions.h5\")\n",
    "\"\"\"\n",
    "###\n",
    "# FUNCTIONS\n",
    "###\n",
    "\n",
    "def readHdF5(filename, path):\n",
    "    \"\"\"\n",
    "    read hdf5 file, dataset\n",
    "    \n",
    "    input\n",
    "        filename (str) - name of hdf5 results\n",
    "        path (str) - abs path to directory\n",
    "        \n",
    "    require \n",
    "        h5py\n",
    "        \n",
    "    method \n",
    "        1. assemble file\n",
    "        2. read file\n",
    "        3. get dataset\n",
    "\n",
    "    return\n",
    "        file, data\n",
    "    \n",
    "    \"\"\"\n",
    "    #1\n",
    "    file = os.path.join(path, filename) \n",
    "    \n",
    "    #2\n",
    "    f = h5py.File(file, 'r')\n",
    "    \n",
    "    #3\n",
    "    dset = f['data']\n",
    "\n",
    "    return dset\n",
    "\n",
    "def getIndexNames():\n",
    "    \n",
    "    \"\"\"\n",
    "    return list of 21097 index names corresponding to sei prediction features\n",
    "    \n",
    "    input\n",
    "        none\n",
    "    method \n",
    "        1. make a list for the index names\n",
    "        2. open the index names file \n",
    "        3. append name to index name list\n",
    "    \n",
    "    return\n",
    "        idxnames (list) - list of index names\n",
    "    \"\"\"\n",
    "    \n",
    "    #1\n",
    "    idxnames = []\n",
    "    \n",
    "    #2\n",
    "    IDXNAMES = \"/wynton/home/ahituv/fongsl/bin/sei-framework/seq_prediction_columns.txt\"\n",
    "    with open(IDXNAMES, \"r\") as reader:\n",
    "        for line in reader:\n",
    "            #3\n",
    "            idxnames.append(line.strip(\"\\n\"))\n",
    "            \n",
    "    return idxnames\n",
    "\n",
    "def arrayToDF(dset):\n",
    "    \n",
    "    \"\"\"\n",
    "    convert np array to pd dataframe \n",
    "\n",
    "    input\n",
    "        dset - np array of arrays\n",
    "    method\n",
    "        1. np.vstack dset, turn into dataframe\n",
    "        2. add column names as index names\n",
    "   \n",
    "   return\n",
    "       df (pd dataframe) - dataframe of the np arrays w reset index\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.DataFrame(np.vstack(dset))\n",
    "    print(df.shape)\n",
    "    df.columns = getIndexNames() # function get column names\n",
    "    \n",
    "    return df.reset_index()\n",
    "\n",
    "def getRowNames(row_textfile, path):\n",
    "    \"\"\"\n",
    "    return list corresponding to sample names\n",
    "\n",
    "    input\n",
    "        row_textfile (str) - file to read w/ rownames\n",
    "        path (str) - path to dir w/ text file\n",
    "    \n",
    "    method\n",
    "        1. make empty dictionary to collect rows, instantiate the file\n",
    "        2. parse through file, add row index, name to dictionary \n",
    "        3. make dictionary into pd dataframe\n",
    "        4. change datatype of index col to int\n",
    "    \n",
    "    return \n",
    "        df (pd dataframe) - dataframe of row labels + \n",
    "            corresponding indexes in prediction file\n",
    "    \"\"\"\n",
    "    \n",
    "     #1\n",
    "    rownames = {}\n",
    "    file = os.path.join(path, row_textfile) \n",
    "    \n",
    "    #2\n",
    "    with open(file, \"r\") as reader:\n",
    "        for line in reader:\n",
    "             \n",
    "            idx, name = line.strip(\"\\n\").split(\"\\t\")\n",
    "            if idx !=\"index\":\n",
    "                rownames[idx]=name\n",
    "    #3            \n",
    "    df = pd.DataFrame(rownames.items(), columns= [\"index_col\", \"id\"])\n",
    "\n",
    "    #4\n",
    "    df[\"index_col\"]=df[\"index_col\"].astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def formatDf(df, names, coor):\n",
    "    \"\"\"\n",
    "    format sei prediction dataframe, \n",
    "    \n",
    "    add \n",
    "        row names\n",
    "        coordinates\n",
    "        pair_id \n",
    "        nullomer \n",
    "    fix\n",
    "        first \"id\" row, which corresponds to the endogenous scaffold sequence\n",
    "        \n",
    "    indput\n",
    "        df (pd dataframe) - dataframe of sei predictions\n",
    "        names (pd dataframe) - dataframe of row names and indexes\n",
    "        coor (str) - coordinates of scaffold sequence\n",
    "    \n",
    "    method\n",
    "        1. merge row names and dataframe predictiosn\n",
    "        2. drop the index columns. we don't need these anymore. \n",
    "        3. fix the id of the first row - endogenous sequence\n",
    "        4. add columns\n",
    "            coordinates\n",
    "            pair_id\n",
    "            nullomer\n",
    "    return \n",
    "        df (pd dataframe) - formatted dataframe. \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    #1 add to dataframe\n",
    "    df = pd.merge(names, df, how=\"left\", left_on =\"index_col\", right_on = \"index\")\n",
    "\n",
    "    #2 drop the index_col name (redundant)\n",
    "    df = df.drop(columns=[\"index_col\", \"index\"])\n",
    "\n",
    "    # format dataframe\n",
    "    #3 first item needs to be renamed as the endogenous sequence. \n",
    "    df.loc[df.index == 0, \"id\"] = f\"{coor}_-1_concat-endog\"\n",
    "    \n",
    "    # 4\n",
    "    df[\"coor\"] = df[\"id\"].apply(lambda x: x.split(\"_\")[0])\n",
    "    df[\"pair_id\"] = df[\"id\"].apply(lambda x: \"_\".join((x.split(\"_\")[1:])))\n",
    "\n",
    "    # add nullomer bool\n",
    "    df[\"nullomer\"] = False \n",
    "    df.loc[df[\"id\"].str.contains(\"null\"), \"nullomer\" ] = True\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def filterCL(df):\n",
    "    \"\"\"\n",
    "    filter dataframe for cell-type specific features\n",
    "    \n",
    "    input\n",
    "        df (pd dataframe) - full dataframe of 21907 predictions + meta columns, rows corresponding to each sequence prediction\n",
    "        \n",
    "    method\n",
    "        1. determin meta-data columns to keep in list. I will add the prediction columns to this list. \n",
    "        2. determine cell lines to filter for\n",
    "        3. per cell line, iterate through 21907 dataframe column names, \n",
    "            adding any column name that contains cell line. \n",
    "            Uses str search. \n",
    "        4. subset dataframe for cl_cols. \n",
    "        \n",
    "    return\n",
    "        df (pd dataframe) - dataframe reduced to only cellline-specific feature predictions. \n",
    "    \n",
    "    \"\"\"\n",
    "    #1\n",
    "    cl_cols = [\"id\", \"coor\",\"pair_id\", \"nullomer\"]\n",
    "    \n",
    "    #2\n",
    "    CLS = [\"K562\", \"HepG2\", \" WTC11\"]\n",
    "    \n",
    "    #3\n",
    "    for cl in CLS:\n",
    "        for col in list(df):\n",
    "            if cl in col:\n",
    "                cl_cols.append(col)\n",
    "    \n",
    "    #4\n",
    "    df = df[cl_cols].drop_duplicates()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def computeFeatureMean(feature, df):\n",
    "    \"\"\"\n",
    "    compute the mean of the feature for kmers, nullomers, and endogenous sequence\n",
    "    \n",
    "    input\n",
    "        feature (str) - name of feature (e.g. H3K4me3) \n",
    "        df (pd dataframe) - prediction datafrme\n",
    "        \n",
    "    method\n",
    "        1. pivot longform dataframe, keeping only feature. \n",
    "            Index is each sample, \n",
    "            Columns are the tracks measuring that feature \n",
    "            (there can be more than one track that measures a feature, like 60-something DHS tracks for k562)\n",
    "            \n",
    "            Values will be the predicted probabilities\n",
    "\n",
    "        2. if there are predictions\n",
    "        3. per column, calculate the mean of each sequence across multiple track measures for one feature.  \n",
    "            (except the first, which is the sample id col) \n",
    "        4. add feature column\n",
    "        5. compute difference between each sample pred and endogenous sequence prediction means\n",
    "        6. compute the rank of each sequence mean \n",
    "        7. compute standard score for distribution of sequence means\n",
    "        \n",
    "    return \n",
    "        dif (pd dataframe) - dataframe of summarized mean scores for the feature, \n",
    "            as well as the difference from the endogenous sequence\n",
    "            \n",
    "    \"\"\"\n",
    "    # pivot dataframe related to feature\n",
    "    dif = pd.pivot(df.loc[df[\"feature\"]==feature], index=\"pair_id\", columns=\"track\",\n",
    "                                 values=\"pred_prob\").reset_index()\n",
    "    if len(dif) >0:\n",
    "\n",
    "        # calculate the mean score\n",
    "        dif[\"mean\"] = dif[dif.columns[1:]].mean(axis=1)\n",
    "\n",
    "        # add feature as a column\n",
    "        dif[\"feature\"] = feature\n",
    "\n",
    "        # calculate distance from kmer to each mutation\n",
    "        dif[\"endog_dif\"] = dif[\"mean\"] - dif.loc[dif[\"pair_id\"].str.contains('endog'), \"mean\"].iloc[0]\n",
    "\n",
    "        # rank the means. \n",
    "        dif[\"mean_rank\"]=dif[\"mean\"].rank()\n",
    "\n",
    "        #dif[\"mean_z\"]=stats.zscore(dif[\"mean\"])\n",
    "\n",
    "        return dif[[\"pair_id\", \"mean\", \"feature\", \"endog_dif\",\"mean_rank\"]]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def getPredValues(dif):\n",
    "    \"\"\"\n",
    "    Calculate the mean of feature means, std for kmers, nullomers, and the endogenous sequence feature means\n",
    "    \n",
    "    input\n",
    "        dif (pd dataframe) - dataframe for one feature, \n",
    "            where means of track predictions are summarized for nullomer, control and endogenous sequences\n",
    "\n",
    "    method\n",
    "        1. get kmer and nullomer mean of means, \n",
    "            as there are multiple nullomer and kmer sequences embedded in the same scaffold,  \n",
    "            and endogenous mean, \n",
    "            for which there is only one sequence and one mean to reflect the track means for that feature\n",
    "        2. compute standard deviation for kmer, nullomer sequence predictions\n",
    "        \n",
    "    return\n",
    "        (list) - list of summary stat values\n",
    "    \"\"\"\n",
    "    kmer_pred = dif.loc[dif[\"pair_id\"].str.contains(\"kmer\"),\"mean\"].mean()\n",
    "    null_pred = dif.loc[dif[\"pair_id\"].str.contains(\"null\"),\"mean\"].mean()\n",
    "    ctrl_pred = dif.loc[~dif[\"pair_id\"].str.contains(\"endog\"),\"mean\"].iloc[0]\n",
    "\n",
    "    kmer_pred_std = dif.loc[dif[\"pair_id\"].str.contains(\"kmer\"),\"mean\"].std()\n",
    "    null_pred_std = dif.loc[dif[\"pair_id\"].str.contains(\"null\"),\"mean\"].std()\n",
    "    \n",
    "    return [kmer_pred, null_pred, ctrl_pred, kmer_pred_std, null_pred_std]\n",
    "    \n",
    "\n",
    "def makeLongForm(celldf):\n",
    "    \"\"\"\n",
    "    turn prediction dataframe from df w/ 21907 columns into longform\n",
    "    \n",
    "    input\n",
    "        celldf (pd dataframe) -  sei prediction df w/ 21907 columns\n",
    "    \n",
    "    method\n",
    "        1. use melt to make long form of data, keeping metadata as columns (id_vars) \n",
    "        2. split track annotations into cell line, feature, and dataset columns\n",
    "        \n",
    "    return \n",
    "        test (pd dataframe) - long-form dataframe w/ cell line, feature, and dataset column annotations\n",
    "        \n",
    "    \"\"\"\n",
    "    # melt dataframe into long form\n",
    "    test = pd.melt(celldf, id_vars=[\"nullomer\", \"coor\", \"pair_id\", \"id\"],\n",
    "                           var_name=\"track\", value_name=\"pred_prob\")\n",
    "    \n",
    "    # annotate cl, feature, and dataset ids\n",
    "    test[\"cl\"] = test[\"track\"].apply(lambda x:x.split(\"|\")[0])\n",
    "    test[\"feature\"] = test[\"track\"].apply(lambda x:x.split(\"|\")[1])\n",
    "    test[\"dataset\"] = test[\"track\"].apply(lambda x:x.split(\"|\")[2])\n",
    "    \n",
    "    return test    \n",
    "    \n",
    "\n",
    "\n",
    "def plotHist(dif, coor, feature, ctrl_pred, out):\n",
    "    \"\"\"\n",
    "    plot histogram distribution of mean scores per feature. \n",
    "    \n",
    "    input\n",
    "        dif (pd dataframe) -  for one feature, prediction means for all nullomer, kmer, and endogenous sequence\n",
    "        coor (str) - genomic locus\n",
    "        ctrl_pred (float) - mean feature prediction for endogenous sequence\n",
    "        out (str) - out file name to use as template for pdf\n",
    "        \n",
    "    method \n",
    "        1. separate data into types {nullomer, kmer, endog}\n",
    "        2. for each type, plot histogram distribution\n",
    "        3. add dashed line for mean of endogenous sequence feature prediction\n",
    "        4. set title, xlabel, legend\n",
    "        5. write pdf\n",
    "    \"\"\"\n",
    "    \n",
    "    #1\n",
    "    dif[\"type\"] = dif[\"pair_id\"].apply(lambda x: x.split(\"-\")[-1])\n",
    "    \n",
    "    #2\n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "\n",
    "    for t in dif[\"type\"].unique():\n",
    "        if t!= \"endog\":\n",
    "        # plot distribution of prediction differences\n",
    "            data = dif.loc[dif[\"type\"]==t, \"mean\"]\n",
    "            sns.histplot(data, label=t, stat=\"percent\")\n",
    "    #3\n",
    "    ax.axvline(ctrl_pred, ls=\"--\", c=\"g\")\n",
    "    \n",
    "    #4 name the plot\n",
    "    ax.set(title=feature,\n",
    "           xlabel=f\"pred - {COOR}\"\n",
    "           )\n",
    "    ax.legend(bbox_to_anchor=(1,1))\n",
    "    \n",
    "    #5\n",
    "    plt.savefig(os.path.join(out.strip(\".tsv\") + f'.{feature}.pdf'), bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "def infoVector(coor, feature, feature_summary_stats):\n",
    "    \"\"\"\n",
    "    make a vector of summary information to write\n",
    "    \n",
    "    input\n",
    "        coor (str) - locus coordinates\n",
    "        feature (str) - feature name\n",
    "        feature_summary_stats (list) - list of summary stats. \n",
    "        \n",
    "    method\n",
    "        1. add meta data to info_vector list\n",
    "        2. extend list w summary stats\n",
    "        3. turn every list item into a str\n",
    "        4. make column list\n",
    "        \n",
    "    return\n",
    "        info (list) - list of meta data and sumamry stats\n",
    "        columns (list) - names of the data in info list. \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # add coordinate and feature names to the list.     \n",
    "    info_vector = [coor, feature] # prediction track\n",
    "    \n",
    "    # add summary stats\n",
    "    info_vector.extend(feature_summary_stats)\n",
    "    \n",
    "    # turn everything into a string\n",
    "    info = [str(i) for i in info_vector]\n",
    "    \n",
    "    # return column names\n",
    "    columns = [\"#coord\",\n",
    "               \"track\", \"predKmer.mean\", \"predNull.mean\",\n",
    "               \"predCtrl\", 'predKmer.std',\"predNull.std\"\n",
    "               ]\n",
    "\n",
    "    return info, columns\n",
    "\n",
    "def main(argv):\n",
    "    \"\"\"\n",
    "    process sei prediction data\n",
    "    \n",
    "    filter for:\n",
    "        - single locus\n",
    "        - HepG2, K562, and WTC11 cell line feature track predictions\n",
    "        \n",
    "    method\n",
    "        1. Get path variable\n",
    "            1.1 str split to get coordinates from file name\n",
    "            1.2 get file row labels\n",
    "            1.3 make the result .tsv file variables one for cl-specific data, one for the summarized feature data\n",
    "        2. if the cl-filtered long form data does not already exist\n",
    "            2.1 read the hdf5 file\n",
    "            2.2 turn hdf5 np array data into pd dataframe\n",
    "            2.3 get the row names\n",
    "            2.4 format dataframe to add meta data\n",
    "            2.5 filter for cell line-specific features\n",
    "            \n",
    "            2.6 write cell line-specific features longform dataframe\n",
    "            2.7 else open cldf data\n",
    "        3. summarize for each feature, turning data into longform\n",
    "        4. mean of datasets belonging to feature per sequence (nullomer, kmer, endogenous)\n",
    "        5. compute the means of the nullomer and kmer means\n",
    "        6. plot histogram if the difference between endogenous and nullomer sequence is greater than 0.05, \n",
    "            and the endogenous sequence has predicted probability of at least 0.1 for that feature. \n",
    "        7. write summarized means for kmer, nullomer, endogenous sequence per feature. \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    #1\n",
    "    PATH = os.path.dirname(FILE)\n",
    "\n",
    "    #1.1 get locus coordinates from file name\n",
    "    COOR = (FILE.split(\"ext4096.\")[1]).split(\"_predictions.h5\")[0]\n",
    "    \n",
    "    #1.2\n",
    "    FILE_LABELS = FILE.split(\"_predictions.h5\")[0] + \"_row_labels.txt\"\n",
    "    \n",
    "    #1.3\n",
    "    OUT_CLDF = os.path.join(PATH, f\"HepG2.K562.Pred.{COOR}.tsv\")\n",
    "    OUT_SUMMARY = os.path.join(PATH, f\"HepG2.K562.Pred.{COOR}.summary.tsv\")\n",
    "    \n",
    "    #2\n",
    "    if os.path.exists(OUT_LONGFORM) is False:\n",
    "        #2.1 read hdf5 file\n",
    "        dset = readHdF5(FILE,PATH)\n",
    "\n",
    "        #2.2 turn data into DF\n",
    "        df = arrayToDF(dset)\n",
    "\n",
    "        #2.3 get row names\n",
    "        names = getRowNames(FILE_LABELS, PATH)\n",
    "\n",
    "        #2.4 format df\n",
    "        df = formatDf(df, names, COOR)\n",
    "\n",
    "        #2.5 keep only data w/ cls\n",
    "        cldf = filterCL(df)\n",
    "\n",
    "        #2.6 write cldf\n",
    "        cldf.drop_duplicates().to_csv(OUT_CLDF, sep='\\t', index=False)\n",
    "\n",
    "        # improve memory efficiency\n",
    "        del df, dset\n",
    "        \n",
    "    else:\n",
    "        print(\"already filtered for cldf\")\n",
    "        cldf = pd.read_csv(OUT_CLDF, sep='\\t')\n",
    "    \n",
    "    #3 compute means, plot hit for locus\n",
    "    with open(OUT_SUMMARY, \"w\") as writer:\n",
    "        \n",
    "        # make into longform\n",
    "        longdf = makeLongForm(cldf)\n",
    "        v = 0\n",
    "        \n",
    "        #4 take mean score for every feature dataset, row-wise\n",
    "        for feature in list(set(longdf[\"feature\"])):\n",
    "\n",
    "            #4 compute the means, change in means from kmer\n",
    "            dif = computeFeatureMean(feature, longdf)\n",
    "            \n",
    "            if len(dif)>0:  # some features are empty\n",
    "\n",
    "                #5 get summary stats about the feature means, ctrl variation\n",
    "                feature_summary_stats = getPredValues(dif)\n",
    "\n",
    "                # unpack summary stats variables\n",
    "                kmer_pred, null_pred, ctrl_pred, kmer_std, null_std = feature_summary_stats\n",
    "\n",
    "                #6 if nullomer and control are different by atleast 0.05 points, and feature is predicted to have some activity\n",
    "                if abs(null_pred - ctrl_pred) > 0.05 and ctrl_pred > 0.1:\n",
    "\n",
    "                    print(feature, COOR, abs(null_pred - ctrl_pred))\n",
    "\n",
    "                    # plot\n",
    "                    plotHist(dif, COOR, feature, ctrl_pred, out)\n",
    "\n",
    "                #7 write data to file\n",
    "                writeinfo, columns = infoVector(COOR,\n",
    "                                                feature, feature_summary_stats)\n",
    "                if v == 0:\n",
    "                    writer.write(\"\\t\".join(columns)+\"\\n\")\n",
    "\n",
    "                writer.write(\"\\t\".join(writeinfo)+\"\\n\")\n",
    "\n",
    "                v += 1\n",
    "\n",
    "        writer.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(sys.argv[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1376cd4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T22:26:06.276545Z",
     "start_time": "2023-04-28T22:26:06.269534Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.703003859668843e-05,\n",
       " 2.0529173626821067e-05,\n",
       " 1.6252199088739872e-06,\n",
       " 0.00036658122436495987,\n",
       " 9.85357966654557e-05]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_summary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "185d2335",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T22:26:22.857390Z",
     "start_time": "2023-04-28T22:26:22.850621Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chr10:133080140-133080340',\n",
       " 'EPC1',\n",
       " '3.703003859668843e-05',\n",
       " '2.0529173626821067e-05',\n",
       " '1.6252199088739872e-06',\n",
       " '0.00036658122436495987',\n",
       " '9.85357966654557e-05']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writeinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dcdfd19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T22:26:41.217510Z",
     "start_time": "2023-04-28T22:26:41.210724Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EPC1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "883aebc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T22:26:51.759118Z",
     "start_time": "2023-04-28T22:26:51.752631Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "385"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39108ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (wynenv)",
   "language": "python",
   "name": "wynenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
