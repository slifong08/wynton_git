{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a30113da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:13:08.729447Z",
     "start_time": "2023-05-31T23:13:06.525561Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Filter COMMON MPRA elements from HepG2, K562, WTC11 \n",
    "\n",
    "Label.\n",
    "\n",
    "Get cell-type-specific + shared elements \n",
    "    - Bedtools intersect elements together.\n",
    "\n",
    "Intersect w/ FANTOM\n",
    "\n",
    "Turn into .fa\n",
    "\n",
    "Quantify GC dinucleotide content. \n",
    "\n",
    "Find cCRE centers -> run through sei\n",
    "    \n",
    "\"\"\"\n",
    "from Bio.SeqUtils import gc_fraction\n",
    "\n",
    "import config_readwrite as crw\n",
    "import glob\n",
    "import gzip\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pybedtools as pbt\n",
    "import sys\n",
    "import subprocess as sp\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff27026a",
   "metadata": {},
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9acaaa2",
   "metadata": {},
   "source": [
    "## load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e47d159a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:13:08.768787Z",
     "start_time": "2023-05-31T23:13:08.742918Z"
    }
   },
   "outputs": [],
   "source": [
    "config_tag = \"config.ini\"\n",
    "config, cfn = crw.read(os.path.join(os.getcwd(), config_tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6f8bbd",
   "metadata": {},
   "source": [
    "## add ccre section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3506128d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:13:10.113177Z",
     "start_time": "2023-05-31T23:13:10.105433Z"
    }
   },
   "outputs": [],
   "source": [
    "SECTION = \"MPRA_AGARWAL\"\n",
    "\n",
    "crw.check(config, SECTION)\n",
    "\n",
    "# write\n",
    "\n",
    "# source datapath\n",
    "SRC = \"/wynton/home/ahituv/fongsl/MPRA/agarwal_2023\"\n",
    "\n",
    "# add cell lines string\n",
    "config[SECTION][\"joint_library\"] = os.path.join(SRC, \"joint_library.csv\")\n",
    "config[SECTION][\"all_cell_types_summary\"] = os.path.join(SRC, \"all_cell_types_summary.csv\")\n",
    "\n",
    "# add source path\n",
    "config[SECTION][\"src\"] = SRC\n",
    "\n",
    "# add output datapath\n",
    "PATH = \"/wynton/home/ahituv/fongsl/nullomers/data/lock\"\n",
    "config[SECTION][\"path\"] = PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793ffe77",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9afb42",
   "metadata": {},
   "source": [
    "## format data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "008e7448",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:13:11.623544Z",
     "start_time": "2023-05-31T23:13:11.610538Z"
    }
   },
   "outputs": [],
   "source": [
    "def formatLibFile(library_file):\n",
    "    \"\"\"\n",
    "    turn library csv file (sup table 6 of agarwal 2023) into bed-like tsv\n",
    "\n",
    "    input\n",
    "        library file (str) - library csv w/ full path\n",
    "\n",
    "    method\n",
    "        1. make the file to write\n",
    "        2. read library file as csv\n",
    "        3. rename columns as first row. \n",
    "        4. get rid of first row w/ column names\n",
    "        5. reformat \"#chr\" column\n",
    "        6. rearrange data as .bed file like, keeping only hg38 annotations\n",
    "        7. keep only the bed columns, write outfile\n",
    "        8. make bed file\n",
    "\n",
    "    return \n",
    "        outfile (str) - .tsv w/ hg38 .bedfile coordinates.\n",
    "        outfile_bed (str) -  hg38 .bedfile coordinates\n",
    "\n",
    "    \"\"\"\n",
    "    # 1\n",
    "    outfile = library_file.strip(\".csv\") + '.tsv'\n",
    "    outfile_bed = library_file.strip(\".csv\") + '.bed'\n",
    "\n",
    "    # 2\n",
    "\n",
    "    df = pd.read_csv(library_file, sep=\",\")\n",
    "\n",
    "    # 3 name columns as first row\n",
    "    df.columns = list(df.iloc[0])\n",
    "\n",
    "    # 4 get rid of header in first row\n",
    "    df = df[1:]\n",
    "\n",
    "    # 5\n",
    "    df[\"#chr\"] = \"chr\" + df[\"chr.hg38\"]\n",
    "\n",
    "    # 6\n",
    "    keep_cols = [\n",
    "        \"#chr\",\n",
    "        'start.hg38',\n",
    "        'stop.hg38',\n",
    "        'str.hg38',\n",
    "        'name',\n",
    "        'category',\n",
    "        \"230nt sequence (15nt 5' adaptor - 200nt element - 15nt 3' adaptor)\"\n",
    "    ]\n",
    "    # 7            ]\n",
    "    keep = df[keep_cols].dropna()\n",
    "\n",
    "    keep.to_csv(outfile, sep='\\t', index=False)\n",
    "\n",
    "    #8\n",
    "\n",
    "    bedcols = [\"#chr\",\n",
    "               'start.hg38',\n",
    "               'stop.hg38',\n",
    "               'name', 'str.hg38']\n",
    "    bed = keep[bedcols].dropna()\n",
    "    bed[['start.hg38','stop.hg38',]] = bed[['start.hg38','stop.hg38',]].astype(int)\n",
    "    bed.dropna().to_csv(outfile_bed, sep='\\t', index=False)\n",
    "\n",
    "    return outfile, outfile_bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3816f3ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:13:11.979440Z",
     "start_time": "2023-05-31T23:13:11.811930Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def makeLibFa(lib_tsvfile):\n",
    "    \"\"\"\n",
    "    write fa file from library file after trimming 230nt hg38 sequence to 200bp test sequence \n",
    "\n",
    "    input\n",
    "        lib_tsvfile (str) - library .tsv file (.bed like)\n",
    "\n",
    "    method\n",
    "        1. make outfile.fa, open for writing fa info\n",
    "        2. parse through library file\n",
    "        3. trim sequence to remove adaptors. \n",
    "        4. make fa name\n",
    "        5. write row to .fa file\n",
    "\n",
    "    return\n",
    "        outfile (str) - path to .fa file\n",
    "\n",
    "    \"\"\"\n",
    "    five_prime, three_prime = set(), set()\n",
    "    # make .fa file to write\n",
    "    outfile = lib_tsvfile.strip(\".tsv\") + \".fa\"\n",
    "\n",
    "    # open the file\n",
    "    writer = open(outfile, \"w\")\n",
    "\n",
    "    # read tsv file\n",
    "    with open(lib_tsvfile, \"r\") as reader:\n",
    "        for line in reader:\n",
    "            if \"#chr\" not in line:\n",
    "\n",
    "                # get info\n",
    "                chr_, start, end, strand, name, cat, seq = line.strip(\n",
    "                    \"\\n\").split(\"\\t\")\n",
    "\n",
    "                # trim sequence adaptors\n",
    "                trim_seq = seq[15:-15]\n",
    "                five_prime.add(seq[:15]), three_prime.add(seq[-15:])\n",
    "\n",
    "                # make fa name\n",
    "                fa_name = f\">{chr_}:{start}-{end}\"#_{strand}_{name}\"\n",
    "                row = f\"{fa_name}\\n{trim_seq}\\n\"\n",
    "\n",
    "                writer.write(row)\n",
    "\n",
    "    reader.close(), writer.close()\n",
    "    print(five_prime, three_prime)\n",
    "    return outfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce45f3d",
   "metadata": {},
   "source": [
    "## FANTOM CAGE-seq intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77ef2aff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:13:12.217465Z",
     "start_time": "2023-05-31T23:13:12.195662Z"
    }
   },
   "outputs": [],
   "source": [
    "# intersect w/ CAGE enhancers \n",
    "\n",
    "def fantomIntersection(bedfile, outdir):\n",
    "    \n",
    "    print(\"intersecting bedfile x FANTOM5\", bedfile)\n",
    "    \n",
    "    CAGE = \"/wynton/home/ahituv/fongsl/FANTOM5/F5.hg38.enhancers.bed.gz\"\n",
    "\n",
    "    # make the outfile \n",
    "    outfile = os.path.join(outdir, bedfile.strip(\".bed\") + \"_x_FANTOM5.bed\")\n",
    "    \n",
    "    # make bed objects\n",
    "    A = pbt.BedTool(bedfile)\n",
    "    B = pbt.BedTool(CAGE)\n",
    "    \n",
    "    # do intersection\n",
    "    A.intersect(B, wa=True, output=outfile)\n",
    "    \n",
    "    return outfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9048c52",
   "metadata": {},
   "source": [
    "## liftOver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d38872a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:13:12.585355Z",
     "start_time": "2023-05-31T23:13:12.577913Z"
    }
   },
   "outputs": [],
   "source": [
    "def liftOver(bedfile, from_build, to_build):\n",
    "    \n",
    "    print(\"liftover from\", from_build, \"to\", \"to_build\", bedfile)\n",
    "    \n",
    "    #1\n",
    "    SCRIPT = \"/wynton/home/ahituv/fongsl/tools/evo/liftover_bed-wynton.py\"\n",
    "    \n",
    "    #2\n",
    "    cmd = [\"python\", \n",
    "           SCRIPT, \n",
    "           bedfile, \n",
    "           \"-f\", from_build, \n",
    "           \"-t\", to_build\n",
    "          ]\n",
    "    \n",
    "    #3\n",
    "    print(\" \".join(cmd))\n",
    "    #sp.call(\" \".join(cmd), shell=True)\n",
    "    \n",
    "    #4\n",
    "    outfile = bedfile.strip(\".bed\") + f\".liftOver.to.{to_build}.bed\"\n",
    "    \n",
    "    return outfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f104de4",
   "metadata": {},
   "source": [
    "## .bed -> .fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47eb7251",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:13:12.941578Z",
     "start_time": "2023-05-31T23:13:12.936902Z"
    }
   },
   "outputs": [],
   "source": [
    "def bed2fa(bedfile, build):\n",
    "    \"\"\"\n",
    "    convert .bed -> .fa using custom script (which uses bedtools' getfasta command)\n",
    "    \n",
    "    input\n",
    "        bedfile (str) - path to filtered bed file\n",
    "        build (str) - genome build\n",
    "        \n",
    "    method\n",
    "        1. make script variable\n",
    "        2. construct command list\n",
    "        3. call command with subprocess\n",
    "        \n",
    "    return\n",
    "        out (str) - resultant .fa file. \n",
    "    \"\"\"\n",
    "    print(\".bed -> .fa\", bedfile)\n",
    "    #1\n",
    "    SCRIPT = \"/wynton/home/ahituv/fongsl/tools/genome/fasta_from_bed.py\"\n",
    "    \n",
    "    #2\n",
    "    cmd = [\"python\", \n",
    "           SCRIPT, \n",
    "           bedfile, \n",
    "           '-b', build,\n",
    "          ]\n",
    "    \n",
    "    #3\n",
    "    print(\" \".join(cmd))\n",
    "    #sp.call(\" \".join(cmd), shell=True)\n",
    "    \n",
    "    #4\n",
    "    out = bedfile.strip(\".bed\") + \".fa\"\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01905ee7",
   "metadata": {},
   "source": [
    "## centering bed file and extending from midpoint\n",
    "- for sei analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e9ee8bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:13:43.645214Z",
     "start_time": "2023-05-31T23:13:43.630313Z"
    }
   },
   "outputs": [],
   "source": [
    "def centerBed(bedfile):\n",
    "\n",
    "    # check for header\n",
    "    is_header = [True if \"#chr\" in list(\n",
    "        pd.read_csv(bedfile, sep='\\t', nrows=1)) else False]\n",
    "\n",
    "    if is_header == True:\n",
    "        df = pd.read_csv(bedfile, sep='\\t').dropna()\n",
    "\n",
    "    else:\n",
    "        df = pd.read_csv(bedfile, sep='\\t', header=None).dropna()\n",
    "\n",
    "        #chr \tstart.hg38 \tstop.hg38 \tstr.hg38 \tname\n",
    "    df.columns = [\"#chr\", \"start\", \"end\", \"id\",  'strand']\n",
    "    df = df.loc[df[\"end\"] != \"stop.hg38\"]\n",
    "    df[[\"start\", \"end\"]]=df[[\"start\", \"end\"]].astype(int)\n",
    "    df[\"len\"] = df[\"end\"]-df[\"start\"] # calculate the length\n",
    "    df[\"center_start\"] = df[\"len\"].astype(int).divide(2).astype(\n",
    "        int) + df[\"start\"]  # find center, int to round,\n",
    "    \n",
    "    # plus 1 so that end is zero coordinate (kind of like SNP)\n",
    "    df[\"center_end\"] = df[\"center_start\"] + 1\n",
    "\n",
    "    outfile = bedfile.strip(\".bed\") + \".centered.bed\"\n",
    "\n",
    "    df[[\"#chr\", \"center_start\", \"center_end\", \"id\"]\n",
    "       ].drop_duplicates().to_csv(outfile, sep='\\t', index=False)\n",
    "\n",
    "    return outfile\n",
    "\n",
    "\n",
    "def extendBed(bedfile, flanksize):\n",
    "    \"\"\"\n",
    "    expand bed\n",
    "\n",
    "    require\n",
    "        bedtools slop\n",
    "        wynton\n",
    "\n",
    "    input\n",
    "        bed (str) - path to bed file\n",
    "        flanksize (int) - length to extend bed coordinates by\n",
    "\n",
    "    method \n",
    "        1. get genome size. \n",
    "        2. make outfile name\n",
    "        3. bedtools slop command\n",
    "\n",
    "    return\n",
    "        out (str) - path to results.bed\n",
    "    \"\"\"\n",
    "    genome = \"/wynton/home/ahituv/fongsl/dna/hg38/hg38.chrom.sizes\"\n",
    "\n",
    "    path, file = os.path.split(bedfile)\n",
    "\n",
    "    outfile = os.path.join(path, file.strip(\".bed\") +\n",
    "                           f\".ext.{flanksize*2}bp.bed\")\n",
    "    cmd = f\"bedtools slop -i {bedfile} -g {genome} -b {flanksize} > {outfile}\"\n",
    "    os.system(cmd)\n",
    "\n",
    "    return outfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2465b2e1",
   "metadata": {},
   "source": [
    "## sei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85cf64fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:13:13.820153Z",
     "start_time": "2023-05-31T23:13:13.815698Z"
    }
   },
   "outputs": [],
   "source": [
    "def launchSei(bedfile, build):\n",
    "\n",
    "    SCRIPT = \"/wynton/home/ahituv/fongsl/bin/sei-framework/sarah_scripts/launch_qsub.py\"\n",
    "    \n",
    "    SEIDIR = os.path.join(os.path.split(bedfile)[0], \"sei_predictions\")\n",
    "    \n",
    "    if os.path.exists(SEIDIR) is False:\n",
    "        os.mkdir(SEIDIR)\n",
    "        \n",
    "    cmd = ['python',\n",
    "           SCRIPT, \n",
    "           bedfile, \n",
    "           build, \n",
    "           SEIDIR\n",
    "          ]\n",
    "    \n",
    "    sp.call(\" \".join(cmd), shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5448c2c",
   "metadata": {},
   "source": [
    "## make kmer space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be1a041a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:13:14.610630Z",
     "start_time": "2023-05-31T23:13:14.605014Z"
    }
   },
   "outputs": [],
   "source": [
    "def makeKmerSpace(fasta, kmer_len):\n",
    "    SCRIPT = \"/wynton/home/ahituv/fongsl/nullomers/bin-lock/make_element_kmer_space.py\"\n",
    "\n",
    "    cmd = [\"python\",\n",
    "           SCRIPT,\n",
    "           fasta,\n",
    "           str(kmer_len),\n",
    "           \"5\",\n",
    "           ]\n",
    "\n",
    "    print(\" \".join(cmd))\n",
    "    sp.call(\" \".join(cmd), shell=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495a65e2",
   "metadata": {},
   "source": [
    "## map between kmer space and genome coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f39974e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:13:15.309571Z",
     "start_time": "2023-05-31T23:13:15.302956Z"
    }
   },
   "outputs": [],
   "source": [
    "def mapKmerSpace(fasta, kmer_len, cl, config):\n",
    "    SCRIPT = \"/wynton/home/ahituv/fongsl/nullomers/bin-lock/map_to_kmer_space.py\"\n",
    "    cmd = [\"python\",\n",
    "           SCRIPT,\n",
    "           fasta,\n",
    "           cl, \n",
    "           str(kmer_len),\n",
    "           \"5\",\n",
    "           config\n",
    "           ]\n",
    "\n",
    "    print(\" \".join(cmd))\n",
    "    sp.call(\" \".join(cmd), shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a76af71",
   "metadata": {},
   "source": [
    "## mutagenize kmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49faf7b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:13:16.004636Z",
     "start_time": "2023-05-31T23:13:15.997610Z"
    }
   },
   "outputs": [],
   "source": [
    "def mutagenizeKmers(cl, kmer_len, nmuts, build, first_order, config):\n",
    "    SCRIPT = \"/wynton/home/ahituv/fongsl/nullomers/bin-lock/mutagenize_kmers.sh\"\n",
    "\n",
    "    cmd = [\"qsub\",\n",
    "           SCRIPT,\n",
    "           cl,\n",
    "           str(kmer_len),\n",
    "           str(nmuts),\n",
    "           build,\n",
    "           first_order,\n",
    "           config\n",
    "           ]\n",
    "\n",
    "    print(\" \".join(cmd))\n",
    "    sp.call(\" \".join(cmd), shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7331fd34",
   "metadata": {},
   "source": [
    "## predict TFBS w/ FIMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12f9ca84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:13:16.812203Z",
     "start_time": "2023-05-31T23:13:16.805673Z"
    }
   },
   "outputs": [],
   "source": [
    "def fimo(cl, kmer_len, nmuts, config):\n",
    "    SCRIPT = \"/wynton/home/ahituv/fongsl/nullomers/bin-lock/fimo_null.sh\"\n",
    "\n",
    "    cmd = [\"qsub\",\n",
    "           SCRIPT,\n",
    "           cl,\n",
    "           str(kmer_len),\n",
    "           str(nmuts),\n",
    "           config\n",
    "           ]\n",
    "\n",
    "    print(\" \".join(cmd))\n",
    "    sp.call(\" \".join(cmd), shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4da03ef",
   "metadata": {},
   "source": [
    "# build datasets for each cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88dcb29d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:13:17.376860Z",
     "start_time": "2023-05-31T23:13:17.372291Z"
    }
   },
   "outputs": [],
   "source": [
    "from_build, to_build = \"hg38\", 'hs1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b171ab04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:13:19.544057Z",
     "start_time": "2023-05-31T23:13:17.817037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AGGACCGGATCAACT'} {'CATTGCGTGAACCGA'}\n"
     ]
    }
   ],
   "source": [
    "# add cell line specific paths, bedfiles.\n",
    "filtered_files = []\n",
    "\n",
    "LIB = config[SECTION][\"joint_library\"]\n",
    "\n",
    "# add section\n",
    "SECTIONCL = \"common\"\n",
    "\n",
    "crw.check(config, SECTIONCL)\n",
    "\n",
    "# format library.csv file -> .tsv, .bed\n",
    "TSV, BED = formatLibFile(LIB)\n",
    "config[SECTIONCL][f\"tsv_{from_build}\"] = TSV\n",
    "config[SECTIONCL][f\"bed_{from_build}\"] = BED\n",
    "\n",
    "# make fa file (hg38)\n",
    "FA = makeLibFa(TSV)\n",
    "config[SECTIONCL][f\"fasta_{from_build}\"] = FA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd9318be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:13:20.895573Z",
     "start_time": "2023-05-31T23:13:20.877583Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/wynton/home/ahituv/fongsl/nullomers/data/lock'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbc88bc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:13:49.417766Z",
     "start_time": "2023-05-31T23:13:48.514558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".bed -> .fa /wynton/home/ahituv/fongsl/MPRA/agarwal_2023/joint_library.center.ext.4096bp.bed\n",
      "python /wynton/home/ahituv/fongsl/tools/genome/fasta_from_bed.py /wynton/home/ahituv/fongsl/MPRA/agarwal_2023/joint_library.center.ext.4096bp.bed -b hg38\n",
      "intersecting bedfile x FANTOM5 /wynton/home/ahituv/fongsl/MPRA/agarwal_2023/joint_library.bed\n"
     ]
    }
   ],
   "source": [
    "# add data output path\n",
    "PATH_CL = os.path.join(PATH,  \"processed\")\n",
    "config[SECTIONCL][\"path\"] = PATH_CL\n",
    "\n",
    "###\n",
    "# hg38\n",
    "###\n",
    "\n",
    "# center and extend filtered.hg38.bed for sei\n",
    "CENTERED_hg38 = centerBed(BED)\n",
    "config[SECTIONCL][f\"bed_centered_{from_build}\"] = CENTERED_hg38\n",
    "\n",
    "EXTENDED_hg38 = extendBed(CENTERED_hg38, 2048)  # extend 2048 bases in each direction for sei\n",
    "config[SECTIONCL][f\"bed_extended_{from_build}\"] = EXTENDED_hg38\n",
    "\n",
    "# center and extend filtered.hg38.bed for sei\n",
    "FA_EXTENDED_hg38 = bed2fa(EXTENDED_hg38, from_build)\n",
    "config[SECTIONCL][f\"fa_extended_{from_build}\"] = FA_EXTENDED_hg38\n",
    "\n",
    "# FANTOM overlap\n",
    "BED_X_FANTOM = fantomIntersection(BED, PATH_CL)\n",
    "config[SECTIONCL][\"xFANTOM\"] = BED_X_FANTOM\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "282637a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:13:51.928908Z",
     "start_time": "2023-05-31T23:13:51.326157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liftover from hg38 to to_build /wynton/home/ahituv/fongsl/MPRA/agarwal_2023/joint_library.bed\n",
      "python /wynton/home/ahituv/fongsl/tools/evo/liftover_bed-wynton.py /wynton/home/ahituv/fongsl/MPRA/agarwal_2023/joint_library.bed -f hg38 -t hs1\n",
      ".bed -> .fa /wynton/home/ahituv/fongsl/MPRA/agarwal_2023/joint_library.liftOver.to.hs1.bed\n",
      "python /wynton/home/ahituv/fongsl/tools/genome/fasta_from_bed.py /wynton/home/ahituv/fongsl/MPRA/agarwal_2023/joint_library.liftOver.to.hs1.bed -b hs1\n",
      ".bed -> .fa /wynton/home/ahituv/fongsl/MPRA/agarwal_2023/joint_library.liftOver.to.hs1.center.ext.4096bp.bed\n",
      "python /wynton/home/ahituv/fongsl/tools/genome/fasta_from_bed.py /wynton/home/ahituv/fongsl/MPRA/agarwal_2023/joint_library.liftOver.to.hs1.center.ext.4096bp.bed -b hs1\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# HS1\n",
    "###\n",
    "\n",
    "# LiftOver - to make kmer space. \n",
    "\n",
    "LIFTED = liftOver(BED, from_build, to_build)\n",
    "config[SECTIONCL][f\"bed_{to_build}\"] = LIFTED\n",
    "    \n",
    "# .bed -> .fa for kmer space\n",
    "FA_LIFTED = bed2fa(LIFTED, to_build)\n",
    "config[SECTIONCL][f\"fasta_{to_build}\"] = FA_LIFTED\n",
    "    \n",
    "# center and extend filtered.hs1.bed for sei\n",
    "CENTERED = centerBed(LIFTED)\n",
    "config[SECTIONCL][f\"bed_centered_{to_build}\"] = CENTERED\n",
    "\n",
    "    \n",
    "EXTENDED = extendBed(CENTERED, 2048)  # extend 2048 bases in each direction for sei\n",
    "config[SECTIONCL][f\"bed_extended_{to_build}\"] = EXTENDED\n",
    "\n",
    "FA_EXTENDED = bed2fa(EXTENDED, to_build)\n",
    "config[SECTIONCL][f\"fa_extended_{to_build}\"] = FA_EXTENDED\n",
    "\n",
    "\n",
    "crw.write(config, cfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5877a506",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T22:36:41.286961Z",
     "start_time": "2023-05-31T22:36:41.202170Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qsub /wynton/home/ahituv/fongsl/nullomers/bin-lock/mutagenize_kmers.sh common 15 2 hs1 True /wynton/home/ahituv/fongsl/nullomers/bin-lock/config.ini\n",
      "Your job 9242317 (\"mutagenize_kmers.sh\") has been submitted\n"
     ]
    }
   ],
   "source": [
    "FA_LIFTED = '/wynton/home/ahituv/fongsl/MPRA/agarwal_2023/joint_library.liftOver.to.hs1.fa'    \n",
    "# make kmer spaces and mutagenize\n",
    "CL = \"common\"\n",
    "NMUTS = 2\n",
    "to_build = 'hs1'\n",
    "for len_k in np.arange(11, 24):\n",
    "    if len_k ==15:\n",
    "        # quantify kmer space\n",
    "        #makeKmerSpace(FA_LIFTED, len_k)\n",
    "    \n",
    "        # map kmer space\n",
    "        # mapKmerSpace(FA_LIFTED, len_k, CL, cfn)\n",
    "    \n",
    "        FO = \"True\" # keep only first order? \n",
    "        \n",
    "        # mutagenize to create nullomers.  \n",
    "        mutagenizeKmers(CL, len_k, NMUTS, to_build, FO, cfn)\n",
    "        \n",
    "        # TFBS motif/ binding prediction\n",
    "        #fimo(CL, len_k, NMUTS, cfn)\n",
    "    \n",
    "    # launch Sei predictions - runs one at a time. Might be best to parallelize in the future. \n",
    "    # launchSei(EXTENDED, from_build)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0f74d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T02:25:57.794148Z",
     "start_time": "2023-04-12T02:25:57.794130Z"
    }
   },
   "outputs": [],
   "source": [
    "FA_EXTENDED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052f0124",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T21:12:41.268386Z",
     "start_time": "2023-04-12T21:12:41.260970Z"
    }
   },
   "outputs": [],
   "source": [
    "9292835/(58593973 + 55384369 + 55406747 + 58350816),(58593973 + 55384369 + 55406747 + 58350816)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72632707",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T21:13:42.806732Z",
     "start_time": "2023-04-12T21:13:42.802425Z"
    }
   },
   "outputs": [],
   "source": [
    "4**14, 9292835/(4**14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c8040f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (wynenv)",
   "language": "python",
   "name": "wynenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
