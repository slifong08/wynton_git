{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae9d4ce4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T21:09:12.695797Z",
     "start_time": "2023-04-14T21:09:12.044007Z"
    },
    "code_folding": [
     144,
     287,
     339,
     377
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTDIR /wynton/home/ahituv/fongsl/MPRA/agarwal_2023/kmers/14mers\n",
      "reading fa /wynton/home/ahituv/fongsl/MPRA/agarwal_2023/joint_library.liftOver.to.hs1.fa\n",
      "n sequences 59172\n",
      "N keys have been run already 15016\n",
      "Counting kmer instances: 0.00011211726814508438\n",
      "Writing dict\n",
      "/wynton/home/ahituv/fongsl/MPRA/agarwal_2023/kmers/14mers/chr1.100068033-100068233.fwd.csv.csv\n",
      "Counting kmer instances: 0.00023621879518032074\n",
      "Writing dict\n",
      "/wynton/home/ahituv/fongsl/MPRA/agarwal_2023/kmers/14mers/chr1.100068033-100068233.rev.csv.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\"\"\"\n",
    "sarahfong\n",
    "\n",
    "Summary\n",
    "    - count kmers per fasta\n",
    "    - split kmer into multiple files where the first N letters of the kmer is the \"key\"\n",
    "    - one file per key will be written w/ counts of sequences associated w/ that key + value\n",
    "\n",
    "Example\n",
    "    Say we find an 11mer, GCGTACGTACG, that appears 15025 times on chrN. The key length is 4. \n",
    "        The key is the first 4 letters \"GCGT\". \n",
    "        The value, or other 7 letters, \"ACGTACG\" will be written to GCGT.csv\n",
    "        The 11mer counts for GCGTACGTACG, will be written to GCGT.csv\n",
    "\n",
    "        The resulting file will look like this:\n",
    "\n",
    "        ./GCGT.csv\n",
    "            ACGTACG, 15025\n",
    "Limitations\n",
    "    - Skips sequences with \"Ns\"\n",
    "            \n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "from Bio.SeqIO.FastaIO import SimpleFastaParser\n",
    "from Bio.Seq import Seq\n",
    "import glob\n",
    "import gzip\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import os, sys\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from functools import partial\n",
    "\"\"\"\n",
    "arg_parser = argparse.ArgumentParser()\n",
    "\n",
    "arg_parser.add_argument(\"fasta\", type=str, help='.fa file to make kmer space from (full path)')\n",
    "arg_parser.add_argument(\"length\", type=int, help='kmer length')\n",
    "arg_parser.add_argument(\"keysize\", type=int, help='kmer key length for storing info')\n",
    "\n",
    "\n",
    "args = arg_parser.parse_args()\n",
    "\n",
    "FASTA, WINDOW_SIZE, KEYSIZE = args.fasta,args.length, args.keysize\n",
    "\n",
    "\"\"\"\n",
    "FASTA=\"/wynton/home/ahituv/fongsl/MPRA/agarwal_2023/joint_library.liftOver.to.hs1.fa\" \n",
    "WINDOW_SIZE=14\n",
    "KEYSIZE=5\n",
    "\n",
    "\n",
    "# get path, name from fasta file. \n",
    "PATH, NAME = os.path.split(FASTA)[0], os.path.split(FASTA)[1].strip('.fa')\n",
    "\n",
    "# make outdirectory for results\n",
    "OUTDIR = os.path.join(PATH, \"kmers\", f\"{WINDOW_SIZE}mers\")\n",
    "\n",
    "print(\"OUTDIR\", OUTDIR) \n",
    "\n",
    "# check to make sure directories exist, or else make them\n",
    "if os.path.exists(OUTDIR) is False:\n",
    "    if os.path.exists(os.path.dirname(OUTDIR)) is False: # make ./kmer dir first\n",
    "        os.mkdir(os.path.dirname(OUTDIR))\n",
    "    os.mkdir(OUTDIR) # make full dir ./kmer/{kmer}mers\n",
    "\n",
    "###\n",
    "# functions\n",
    "###\n",
    "\n",
    "def array_reader(array, job_number):\n",
    "    \"\"\"\n",
    "    read array, return value matching job number\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(array, \"r\") as reader:\n",
    "        for line in reader:\n",
    "            num, chr_num = line.strip(\"\\n\").split(\"\\t\")\n",
    "            if int(num) == int(job_number):\n",
    "                CHR_NUM = chr_num\n",
    "            \n",
    "    return CHR_NUM\n",
    "\n",
    "# ## extract fa sequence\n",
    "def extractFaSeq(fasta):\n",
    "    \"\"\"\n",
    "    get fasta sequence, reverse complement\n",
    "\n",
    "    require\n",
    "        Bio.SeqIO.FastaIO - SimpleFastaParser\n",
    "        gzip (if zipped)\n",
    "\n",
    "    input\n",
    "        chr_num (str) - chromosome number e.g. 1,2,3,X,Y\n",
    "        path (str) - path to .fa files\n",
    "\n",
    "    method\n",
    "        1. make empty seq dictionary to collect sequences \n",
    "        2. open fa file\n",
    "        3. get sequence w/ simpleFastaParser\n",
    "        4. get reverse complement by turning seq into Seq object\n",
    "\n",
    "    return \n",
    "        seqs (dict) - dictionary of forward and reverse sequences per element\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"reading fa\", fasta)\n",
    "\n",
    "    #1\n",
    "    seqs = {}\n",
    "    \n",
    "    #2\n",
    "    if \".gz\" in fasta:\n",
    "        handle = gzip.open(fasta, \"rt\")\n",
    "    else:\n",
    "        handle = open(fasta, \"r\")\n",
    "\n",
    "    #3 read using simpleFastaParser \n",
    "        \n",
    "    for val in SimpleFastaParser(handle):\n",
    "        seq_id, fwd = val\n",
    "        \n",
    "        #4 reverse complement\n",
    "        rev = str(Seq(fwd).reverse_complement())\n",
    "        \n",
    "        \n",
    "        seqs[seq_id] = (fwd, rev)\n",
    "    \n",
    "    print(\"n sequences\", len(seqs.keys()))\n",
    "            \n",
    "    return seqs\n",
    "\n",
    "# make key-mer universe\n",
    "\n",
    "def makeKeys(keysize):\n",
    "    \"\"\"\n",
    "    input\n",
    "        keysize (int) - length of kmer-keys to create\n",
    "\n",
    "    require\n",
    "        itertools.product\n",
    "        python list comprehension\n",
    "\n",
    "    method\n",
    "        itertools.product kmers -> join kmers into str -> make list\n",
    "\n",
    "\n",
    "    return\n",
    "        key_set (set) - list of strings. \n",
    "    \"\"\" \n",
    "    key_set = set()\n",
    "    for item in product(\"ACGT\", repeat=keysize):\n",
    "        key_set.add(\"\".join(item))\n",
    "\n",
    "\n",
    "    return key_set\n",
    "\n",
    "# ## retreive one kmer\n",
    "# \n",
    "# ### !Major question! What to do about N's\n",
    "\n",
    "\n",
    "def getOneSeqKmers(windowsize, sequence):\n",
    "\n",
    "    \"\"\"\n",
    "    get 1 sequence; break up sequence into equally sized kmers w sliding window of with windowsize, stepsize of 1\n",
    "    \n",
    "    required packages\n",
    "        - numpy\n",
    "        \n",
    "    inputs\n",
    "        \n",
    "        windowsize (int) - windowsize to make for sequence\n",
    "        sequence (str) - sequence to break into kmers\n",
    "\n",
    "        \n",
    "    method\n",
    "        1. quantify the number of starts per sequence, given length. \n",
    "        2. make empty kmer list, then iterate through start positions, getting kmers. \n",
    "        3. Append to kmer list if kmer does not have N in sequence\n",
    "    \n",
    "    return \n",
    "        kmer_list (str) - windowsize from input sequence\n",
    "        \n",
    "    \"\"\"\n",
    "    #1\n",
    "    STARTS = list(range(len(sequence) - windowsize + 1))\n",
    "    \n",
    "    #2\n",
    "    kmer_list = []\n",
    "    \n",
    "    for start in STARTS:\n",
    "        kmer = sequence[start:start+windowsize].upper()\n",
    "\n",
    "        #3\n",
    "        if \"N\" not in kmer.upper(): # append sequence windows within range of possible windows\n",
    "            kmer_list.append(kmer)\n",
    "    \n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return kmer_list\n",
    "    \n",
    "\n",
    "# ## count kmers in universe\n",
    "\n",
    "def countKmersUniverse(kmer_list, keysize):\n",
    "    \"\"\"\n",
    "    add kmer counts to chromosome universe dictionary:\n",
    "\n",
    "    input\n",
    "        kmer_list (list) - list of lists of kmers in fasta sequences (forward and reverse)\n",
    "\n",
    "    method\n",
    "        1. build kmer-universe dict while parsing kmers\n",
    "        2. add kmer counts to dictionary, removing NoneType instances. \n",
    "            2.1 get key-specific dictionary from universe dictionary\n",
    "            2.2 if value sequence is not in key dictionary, add. \n",
    "            2.3 if value sequence has been seen, increase dictionary value count. \n",
    "        3. print timer\n",
    "\n",
    "    return\n",
    "        universe_dict (dictionary) - chromosome universe w/ kmer counts. \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # 1\n",
    "    universe_dict = {}\n",
    "\n",
    "    start = timer()\n",
    "\n",
    "    # 2 count kmers from forward, reverse lists (kmer_list is list of lists) dictionary\n",
    "    for l in kmer_list:\n",
    "        for i in l:\n",
    "\n",
    "            if i is not None:\n",
    "\n",
    "                # split string into key, value\n",
    "                key, value = i[:keysize], i[keysize:]\n",
    "\n",
    "                # if key is not in universe dictionary, add the key\n",
    "                if key not in universe_dict:\n",
    "                    universe_dict[key] = {}\n",
    "\n",
    "                # 2.1 get the key dictionary from universe dictionary\n",
    "                keydict = universe_dict[key]\n",
    "\n",
    "                # 2.2 start count when value sequence is not in dictionary\n",
    "                if value not in keydict:\n",
    "                    keydict[value] = 1\n",
    "\n",
    "                # 2.3 add count of value sequences in key dictionary in universe dictionary\n",
    "                else:\n",
    "                    keydict[value] += 1\n",
    "\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    end = timer()\n",
    "\n",
    "    print(\"Counting kmer instances:\", end-start)\n",
    "\n",
    "    return universe_dict\n",
    "\n",
    "\n",
    "# ## write dictionary\n",
    "\n",
    "def writeDictionary(name, outpath, windowsize, result_dict): # keyset\n",
    "    \"\"\"\n",
    "    write kmer universe dictionary to outfile\n",
    "\n",
    "    input\n",
    "        chr_num (str) - chr number or all\n",
    "        path (str) - path to write outfile\n",
    "        windowsize (int) - size of window used for kmers\n",
    "        results_dict (dictionary) - kmer universe w/ counts of kmer occurrences \n",
    "\n",
    "    method\n",
    "        1. create the outfile per element\n",
    "        2. if not already written (log_key not in keyset), write key, value as comma-separated str to outfile\n",
    "        3. close the outfile\n",
    "        4. compress outfile\n",
    "        5. write outfile log_key to the log\n",
    "\n",
    "    return \n",
    "        query (str) - written file name w asterisks for the key\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"Writing dict\")\n",
    "\n",
    "    \n",
    "    # 1 make the outfile for each element\n",
    "    log_key = \".\".join(name.split(\":\"))\n",
    "    out_file = os.path.join(outpath, f\"{log_key}.csv\")\n",
    "\n",
    "    # 2 parse through sequences per element\n",
    "    with open(out_file, \"w\") as writer:\n",
    "        for key, value in result_dict.items():\n",
    "\n",
    "            # write the values\n",
    "\n",
    "            for secondkey, count in value.items():\n",
    "\n",
    "                writer.write(f\"{key+secondkey},{count}\\n\")\n",
    "        # 3\n",
    "        writer.close()\n",
    "\n",
    "    # 4\n",
    "    os.system(f\"gzip {out_file}\")\n",
    "\n",
    "    # 5 write outfile to log\n",
    "    writeRunLog(name, outpath)\n",
    "\n",
    "    query = os.path.join(outpath, f\"{out_file}.csv\")\n",
    "\n",
    "    return query\n",
    "\n",
    "\n",
    "def readRunLog(path):\n",
    "    \"\"\"\n",
    "    read chr.log and determine whether chromosome has already been summed into file dataset\n",
    "\n",
    "   input\n",
    "        chr_num (str) - chromosome number\n",
    "        path (str) - path to directory to write log\n",
    "\n",
    "    method\n",
    "        1. make the log file\n",
    "            1.1 if log file does not exist, return False (none of the chromosomes have been run) \n",
    "        2. open existing log file. \n",
    "        3. append chr_num to list\n",
    "        4. check whether input chr_num is in list:\n",
    "            4.1 if yes, return True (chromosome has been run)\n",
    "            4.2 if no, return False (chromos dome has not been run)\n",
    "\n",
    "    return\n",
    "        empty set\n",
    "        runset (set) - if key has been added to final nullomer count\n",
    "    \"\"\"\n",
    "\n",
    "    # 1\n",
    "    out = os.path.join(path, \"kmer.log\")\n",
    "\n",
    "    # 2\n",
    "    runset = set()\n",
    "    if os.path.exists(out) is True:\n",
    "\n",
    "        with open(out, \"r\") as runlog:\n",
    "            # 3\n",
    "            for line in runlog.readlines():\n",
    "                runset.add(str(line.split(\"\\n\")[0]))\n",
    "\n",
    "    print(\"N keys have been run already\", len(runset))\n",
    "    return runset\n",
    "\n",
    "\n",
    "def writeRunLog(key, path):\n",
    "    \"\"\"\n",
    "    write log of chrs written to the all mer\n",
    "\n",
    "    input\n",
    "        chr_num (str) - chromosome number\n",
    "        path (str) - path to directory to write log\n",
    "\n",
    "    method\n",
    "        1. make the log file\n",
    "        2. open the log file\n",
    "        3. append the chr_num to the log file\n",
    "        4. close the file\n",
    "    \"\"\"\n",
    "    # 1\n",
    "    out = os.path.join(path, \"kmer.log\")\n",
    "\n",
    "    # 2\n",
    "    with open(out, \"a\") as runlog:\n",
    "\n",
    "        # 3\n",
    "        runlog.write(f\"{key}\\n\")\n",
    "\n",
    "    # 4\n",
    "    runlog.close()\n",
    "\n",
    "    # print(f\"wrote {chr_num} to kmer.log\", out)\n",
    "\n",
    "###\n",
    "# main\n",
    "###\n",
    "\n",
    "def main(argv):\n",
    "   \n",
    "\n",
    " \n",
    "\n",
    "    \"\"\"\n",
    "    per chromosome, write kmer count frequency dictionary as csv\n",
    "    \n",
    "    input\n",
    "        chr_num (str) - chromozome number to process kmers for\n",
    "        path (str) - path to fa files, and to write\n",
    "        window_size (int) - size of window to consider for kmer\n",
    "    \n",
    "    method\n",
    "        0. get chr num from job+num and array\n",
    "        1. get sequence +/- from fa\n",
    "        2. generate set of keys to write kmer-space to. Keys will be used to quantify the known-kmer space.\n",
    "            2.1 check to make sure you haven't run this already. \n",
    "        \n",
    "        \n",
    "        4. get all kmers from sequence in forward and reverse, extend to make one list of lists\n",
    "        \n",
    "        5. count kmers found in fasta\n",
    "        7. write dictionary to .csv\n",
    "\n",
    "    return\n",
    "        outcsv (str) - csvs of kmer universe, separated by keys\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # 0\n",
    "    # NAME = array_reader(ARRAY, JOB_NUM)\n",
    "\n",
    "    # 1 get chr sequence, reverse complement\n",
    "    SEQ = extractFaSeq(FASTA)\n",
    "\n",
    "    # 2 get kmer key set, universe dict\n",
    "    KEY_SET = makeKeys(KEYSIZE)\n",
    "\n",
    "    # 2.1 \n",
    "    run_already = readRunLog(OUTDIR)  # check whether key has been run already\n",
    "\n",
    "    WRITE_KEYS = set(KEY_SET).difference(run_already)\n",
    "\n",
    "    #4 get kmer sequence space \n",
    "    for seq_id, seq_tuple in SEQ.items():\n",
    "        result_multi=[]\n",
    "        for sequence, strand in zip(seq_tuple, [\"fwd\", \"rev\"]):\n",
    "            result_multi.append(getOneSeqKmers(WINDOW_SIZE, sequence))\n",
    "\n",
    "            # 5 count knownmers in kmer universe\n",
    "            genome_kmers = countKmersUniverse(result_multi, KEYSIZE)\n",
    "\n",
    "            #6 write dictionary\n",
    "            outcsv = writeDictionary(seq_id+ f\".{strand}\", OUTDIR, WINDOW_SIZE, genome_kmers) #, WRITE_KEYS)\n",
    "\n",
    "            print(outcsv)\n",
    "        break\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(sys.argv[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdf4b90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (wynenv)",
   "language": "python",
   "name": "wynenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
